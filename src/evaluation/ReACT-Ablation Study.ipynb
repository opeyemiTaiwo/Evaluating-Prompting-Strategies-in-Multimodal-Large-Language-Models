{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPXp/IwV7RzEuIuQWzsMFit"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-YDLvrxD5gw","executionInfo":{"status":"ok","timestamp":1762199206728,"user_tz":300,"elapsed":20866,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"74acccc8-fbaf-4b25-af2f-caed2a543ba9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["\"\"\"\n","Multi-Model ReAct Ablation Study\n","Tests ReAct phase importance across Gemini, GPT-4, and Claude\n","Processes every 90th frame from crime video data\n","\"\"\"\n","\n","import os\n","import json\n","import base64\n","import requests\n","import time\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","from typing import Dict, List, Optional\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from datetime import datetime\n","from collections import defaultdict\n","from tqdm import tqdm\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Mount Google Drive if in Colab\n","try:\n","    from google.colab import drive\n","    if not os.path.exists('/content/drive'):\n","        drive.mount('/content/drive')\n","        print(\"‚úì Google Drive mounted\")\n","except:\n","    pass\n","\n","# Set style\n","sns.set_style(\"whitegrid\")\n","plt.rcParams['figure.figsize'] = (18, 12)\n","\n","# Configuration\n","API_KEYS_DIR = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/SAVE/FINAL-COMPLETED/API-KEYS\"\n","DATA_DIR = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\"\n","SAVE_DIR = \"/content/drive/MyDrive/multi_model_ablation_results\"\n","FRAME_SKIP = 90  # Process every 90th frame\n","CHUNK_SIZE = 10  # Frames per API call\n","\n","\n","class MultiModelReActAgent:\n","    \"\"\"ReAct Agent that works with multiple models\"\"\"\n","\n","    def __init__(self, model_name: str, api_key: str, phases: List[str], config_name: str):\n","        \"\"\"\n","        Initialize agent for specific model\n","\n","        Args:\n","            model_name: 'gemini', 'gpt', or 'claude'\n","            api_key: API key for the model\n","            phases: Enabled ReAct phases ['thought', 'decision', 'observation']\n","            config_name: Configuration name (e.g., 'Full ReAct')\n","        \"\"\"\n","        self.model_name = model_name\n","        self.api_key = api_key\n","        self.phases = phases\n","        self.config_name = config_name\n","        self.history = []\n","\n","        # Model-specific setup\n","        if model_name == 'gemini':\n","            self.model_id = \"gemini-2.0-flash-exp\"\n","            self.base_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{self.model_id}:generateContent\"\n","        elif model_name == 'gpt':\n","            self.model_id = \"gpt-4o\"\n","            self.base_url = \"https://api.openai.com/v1/chat/completions\"\n","        elif model_name == 'claude':\n","            self.model_id = \"claude-sonnet-4-20250514\"\n","            self.base_url = \"https://api.anthropic.com/v1/messages\"\n","\n","        self.prompt_template = self._create_prompt_template()\n","\n","    def _create_prompt_template(self) -> str:\n","        \"\"\"Create phase-specific prompt template\"\"\"\n","        base_intro = \"\"\"Analyze these frames from a crime surveillance video. \"\"\"\n","\n","        phase_instructions = []\n","\n","        if 'thought' in self.phases:\n","            phase_instructions.append(\"\"\"\n","1. THOUGHT/REASONING: Carefully analyze what you observe:\n","   - Identify people, their appearances, and positions\n","   - Note actions, behaviors, and movements\n","   - Observe objects, items, and spatial relationships\n","   - Consider temporal sequence of events\n","   - Reason about what these observations might indicate\n","\"\"\")\n","\n","        if 'decision' in self.phases:\n","            phase_instructions.append(\"\"\"\n","2. DECISION/ACTION: Based on your reasoning, decide:\n","   - What specific aspects require closer analysis?\n","   - What actions or focus areas are most important?\n","   - What should be prioritized in the investigation?\n","   - Rate severity/priority level (HIGH/MEDIUM/LOW)\n","\"\"\")\n","\n","        if 'observation' in self.phases:\n","            phase_instructions.append(\"\"\"\n","3. OBSERVATION/FEEDBACK: Provide detailed observations:\n","   - Document specific evidence you notice\n","   - Note confirming or contradicting details\n","   - Describe environmental context\n","   - Record temporal progression of events\n","\"\"\")\n","\n","        conclusion = \"\"\"\n","FINAL ANALYSIS:\n","- What crime or incident appears to be occurring?\n","- Who are the individuals involved (describe without names)?\n","- What evidence supports your conclusion?\n","- Confidence level (HIGH/MEDIUM/LOW)\n","\n","Analyzing frames {frame_range} of {total_frames}.\n","\"\"\"\n","\n","        return base_intro + \"\".join(phase_instructions) + conclusion\n","\n","    def process_frames(self, frames_data: List[str], frame_range: str, total_frames: int) -> Dict:\n","        \"\"\"Process frames with the model\"\"\"\n","        prompt = self.prompt_template.format(\n","            frame_range=frame_range,\n","            total_frames=total_frames\n","        )\n","\n","        try:\n","            if self.model_name == 'gemini':\n","                return self._process_gemini(frames_data, prompt)\n","            elif self.model_name == 'gpt':\n","                return self._process_gpt(frames_data, prompt)\n","            elif self.model_name == 'claude':\n","                return self._process_claude(frames_data, prompt)\n","        except Exception as e:\n","            return {\"error\": str(e), \"analysis\": None}\n","\n","    def _process_gemini(self, frames_data: List[str], prompt: str) -> Dict:\n","        \"\"\"Process with Gemini\"\"\"\n","        parts = [{\"text\": prompt}]\n","\n","        for frame in frames_data:\n","            parts.append({\n","                \"inline_data\": {\n","                    \"mime_type\": \"image/png\",\n","                    \"data\": frame\n","                }\n","            })\n","\n","        payload = {\n","            \"contents\": [{\"parts\": parts}],\n","            \"generationConfig\": {\n","                \"temperature\": 0.1,\n","                \"maxOutputTokens\": 4096,\n","                \"topP\": 0.8,\n","                \"topK\": 10\n","            }\n","        }\n","\n","        url = f\"{self.base_url}?key={self.api_key}\"\n","        response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, json=payload)\n","\n","        if response.status_code != 200:\n","            return {\"error\": f\"API Error {response.status_code}\", \"analysis\": None}\n","\n","        result = response.json()\n","        if \"candidates\" in result and result[\"candidates\"]:\n","            if \"content\" in result[\"candidates\"][0]:\n","                analysis = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n","                return {\"analysis\": analysis, \"phases_used\": self.phases}\n","\n","        return {\"error\": \"No valid response\", \"analysis\": None}\n","\n","    def _process_gpt(self, frames_data: List[str], prompt: str) -> Dict:\n","        \"\"\"Process with GPT-4\"\"\"\n","        messages = [\n","            {\n","                \"role\": \"system\",\n","                \"content\": f\"You are an expert crime analyst using {self.config_name} approach. Enabled phases: {', '.join(self.phases).upper()}.\"\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": [\n","                    {\"type\": \"text\", \"text\": prompt}\n","                ]\n","            }\n","        ]\n","\n","        # Add images\n","        for frame in frames_data:\n","            messages[1][\"content\"].append({\n","                \"type\": \"image_url\",\n","                \"image_url\": {\n","                    \"url\": f\"data:image/png;base64,{frame}\",\n","                    \"detail\": \"high\"\n","                }\n","            })\n","\n","        payload = {\n","            \"model\": self.model_id,\n","            \"messages\": messages,\n","            \"max_tokens\": 4096,\n","            \"temperature\": 0.1\n","        }\n","\n","        headers = {\n","            \"Content-Type\": \"application/json\",\n","            \"Authorization\": f\"Bearer {self.api_key}\"\n","        }\n","\n","        response = requests.post(self.base_url, headers=headers, json=payload)\n","\n","        if response.status_code != 200:\n","            return {\"error\": f\"API Error {response.status_code}\", \"analysis\": None}\n","\n","        result = response.json()\n","        if \"choices\" in result and result[\"choices\"]:\n","            analysis = result[\"choices\"][0][\"message\"][\"content\"]\n","            return {\"analysis\": analysis, \"phases_used\": self.phases}\n","\n","        return {\"error\": \"No valid response\", \"analysis\": None}\n","\n","    def _process_claude(self, frames_data: List[str], prompt: str) -> Dict:\n","        \"\"\"Process with Claude\"\"\"\n","        content = [{\"type\": \"text\", \"text\": prompt}]\n","\n","        # Add images\n","        for frame in frames_data:\n","            content.append({\n","                \"type\": \"image\",\n","                \"source\": {\n","                    \"type\": \"base64\",\n","                    \"media_type\": \"image/png\",\n","                    \"data\": frame\n","                }\n","            })\n","\n","        payload = {\n","            \"model\": self.model_id,\n","            \"max_tokens\": 4096,\n","            \"temperature\": 0.1,\n","            \"system\": f\"You are an expert crime analyst using {self.config_name} approach. Enabled phases: {', '.join(self.phases).upper()}.\",\n","            \"messages\": [\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": content\n","                }\n","            ]\n","        }\n","\n","        headers = {\n","            \"Content-Type\": \"application/json\",\n","            \"x-api-key\": self.api_key,\n","            \"anthropic-version\": \"2023-06-01\"\n","        }\n","\n","        response = requests.post(self.base_url, headers=headers, json=payload)\n","\n","        if response.status_code != 200:\n","            return {\"error\": f\"API Error {response.status_code}\", \"analysis\": None}\n","\n","        result = response.json()\n","        if \"content\" in result and result[\"content\"]:\n","            analysis = result[\"content\"][0][\"text\"]\n","            return {\"analysis\": analysis, \"phases_used\": self.phases}\n","\n","        return {\"error\": \"No valid response\", \"analysis\": None}\n","\n","\n","class CrimeDataLoader:\n","    \"\"\"Load crime video frames\"\"\"\n","\n","    def __init__(self, data_path: str, frame_skip: int = 90):\n","        self.data_path = Path(data_path)\n","        self.frame_skip = frame_skip\n","\n","    def discover_all_videos(self) -> Dict[str, Dict]:\n","        \"\"\"Discover all videos\"\"\"\n","        print(f\"\\n=== DISCOVERING VIDEOS ===\")\n","        print(f\"Scanning: {self.data_path}\")\n","\n","        all_videos = {}\n","\n","        try:\n","            crime_types = [d for d in os.listdir(self.data_path)\n","                          if os.path.isdir(os.path.join(self.data_path, d))]\n","\n","            print(f\"Found {len(crime_types)} crime types: {crime_types}\")\n","\n","            for crime_type in crime_types:\n","                crime_dir = os.path.join(self.data_path, crime_type)\n","                all_files = os.listdir(crime_dir)\n","\n","                video_groups = defaultdict(list)\n","\n","                for filename in all_files:\n","                    if not any(filename.lower().endswith(ext)\n","                             for ext in ['.png', '.jpg', '.jpeg', '.bmp']):\n","                        continue\n","\n","                    video_id = self._extract_video_id(filename)\n","                    if video_id:\n","                        video_groups[video_id].append(filename)\n","\n","                print(f\"  {crime_type}: {len(video_groups)} videos\")\n","\n","                for video_id, frames in video_groups.items():\n","                    all_videos[f\"{crime_type}_{video_id}\"] = {\n","                        'crime_type': crime_type,\n","                        'video_id': video_id,\n","                        'frames': sorted(frames, key=self._extract_frame_number),\n","                        'crime_dir': crime_dir\n","                    }\n","\n","        except Exception as e:\n","            print(f\"Error: {str(e)}\")\n","\n","        print(f\"Total videos: {len(all_videos)}\")\n","        return all_videos\n","\n","    def _extract_video_id(self, filename: str) -> str:\n","        \"\"\"Extract video ID from filename\"\"\"\n","        import re\n","        name_without_ext = os.path.splitext(filename)[0]\n","\n","        if '_frame_' in name_without_ext:\n","            return name_without_ext.split('_frame_')[0]\n","\n","        parts = name_without_ext.split('_')\n","        if len(parts) >= 2:\n","            try:\n","                int(parts[-1])\n","                return '_'.join(parts[:-1])\n","            except ValueError:\n","                pass\n","\n","        video_id = re.sub(r'_?\\d+$', '', name_without_ext)\n","        if video_id and video_id != name_without_ext:\n","            return video_id\n","\n","        return name_without_ext\n","\n","    def _extract_frame_number(self, filename: str) -> int:\n","        \"\"\"Extract frame number for sorting\"\"\"\n","        import re\n","        try:\n","            if '_frame_' in filename:\n","                parts = filename.split('_frame_')\n","                if len(parts) > 1:\n","                    return int(parts[1].split('.')[0])\n","            numbers = re.findall(r'\\d+', filename)\n","            if numbers:\n","                return int(numbers[-1])\n","        except:\n","            pass\n","        return 0\n","\n","    def load_video_frames(self, video_info: Dict) -> List[str]:\n","        \"\"\"Load frames (every 90th frame)\"\"\"\n","        crime_dir = video_info['crime_dir']\n","        all_frames = video_info['frames']\n","\n","        selected_frames = all_frames[::self.frame_skip]\n","\n","        frames_data = []\n","        for frame_file in selected_frames:\n","            frame_path = os.path.join(crime_dir, frame_file)\n","            try:\n","                with open(frame_path, 'rb') as f:\n","                    frame_data = base64.b64encode(f.read()).decode('utf-8')\n","                    frames_data.append(frame_data)\n","            except Exception as e:\n","                print(f\"  Error loading {frame_file}: {str(e)}\")\n","\n","        return frames_data\n","\n","\n","class MultiModelAblationStudy:\n","    \"\"\"Conduct ablation study across multiple models\"\"\"\n","\n","    def __init__(self, api_keys: Dict[str, str], data_path: str, frame_skip: int = 90):\n","        self.api_keys = api_keys\n","        self.data_loader = CrimeDataLoader(data_path, frame_skip)\n","        self.frame_skip = frame_skip\n","        self.chunk_size = CHUNK_SIZE\n","\n","        # Create agents for each model and configuration\n","        self.models = {}\n","        for model_name, api_key in api_keys.items():\n","            self.models[model_name] = {\n","                'Full ReAct': MultiModelReActAgent(\n","                    model_name, api_key,\n","                    ['thought', 'decision', 'observation'],\n","                    'Full ReAct'\n","                ),\n","                'No Decision': MultiModelReActAgent(\n","                    model_name, api_key,\n","                    ['thought', 'observation'],\n","                    'No Decision'\n","                ),\n","                'No Observation': MultiModelReActAgent(\n","                    model_name, api_key,\n","                    ['thought', 'decision'],\n","                    'No Observation'\n","                ),\n","                'Only Thought': MultiModelReActAgent(\n","                    model_name, api_key,\n","                    ['thought'],\n","                    'Only Thought'\n","                )\n","            }\n","\n","        self.results = defaultdict(lambda: defaultdict(lambda: defaultdict(dict)))\n","        os.makedirs(SAVE_DIR, exist_ok=True)\n","        print(f\"Results will be saved to: {SAVE_DIR}\")\n","\n","    def run_study(self, max_videos: int = None) -> Dict:\n","        \"\"\"Run ablation study across all models\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"MULTI-MODEL REACT ABLATION STUDY\")\n","        print(f\"Testing {len(self.models)} models √ó 4 configurations\")\n","        print(f\"Processing every {self.frame_skip}th frame\")\n","        print(\"=\"*80 + \"\\n\")\n","\n","        # Discover videos\n","        all_videos = self.data_loader.discover_all_videos()\n","\n","        if not all_videos:\n","            print(\"No videos found!\")\n","            return {}\n","\n","        videos_to_process = list(all_videos.items())\n","        if max_videos:\n","            videos_to_process = videos_to_process[:max_videos]\n","            print(f\"‚ö† Processing {max_videos} videos for testing\\n\")\n","\n","        # Process each video with each model and configuration\n","        for video_key, video_info in tqdm(videos_to_process, desc=\"Videos\"):\n","            print(f\"\\n--- {video_key} ---\")\n","            print(f\"Crime type: {video_info['crime_type']}\")\n","\n","            # Load frames\n","            frames_data = self.data_loader.load_video_frames(video_info)\n","\n","            if not frames_data:\n","                print(\"  No frames loaded\")\n","                continue\n","\n","            print(f\"  Loaded {len(frames_data)} frames\")\n","\n","            # Split into chunks\n","            frame_chunks = [frames_data[i:i+self.chunk_size]\n","                          for i in range(0, len(frames_data), self.chunk_size)]\n","\n","            # Test each model\n","            for model_name in self.models.keys():\n","                print(f\"\\n  Model: {model_name.upper()}\")\n","\n","                # Test each configuration\n","                for config_name, agent in self.models[model_name].items():\n","                    print(f\"    Config: {config_name}\", end=\" \")\n","\n","                    chunk_analyses = []\n","                    processing_times = []\n","\n","                    for chunk_idx, chunk in enumerate(frame_chunks):\n","                        frame_start = chunk_idx * self.chunk_size + 1\n","                        frame_end = min((chunk_idx + 1) * self.chunk_size, len(frames_data))\n","                        frame_range = f\"{frame_start}-{frame_end}\"\n","\n","                        start_time = time.time()\n","                        result = agent.process_frames(chunk, frame_range, len(frames_data))\n","                        processing_time = time.time() - start_time\n","                        processing_times.append(processing_time)\n","\n","                        if result.get('analysis'):\n","                            chunk_analyses.append(result['analysis'])\n","                        elif result.get('error'):\n","                            print(f\"‚ö†\", end=\" \")\n","\n","                        time.sleep(2)  # Rate limiting\n","\n","                    # Extract prediction\n","                    prediction = self._extract_prediction(chunk_analyses)\n","                    ground_truth = self._get_ground_truth(video_info['crime_type'])\n","\n","                    # Store results\n","                    self.results[video_key][model_name][config_name] = {\n","                        'prediction': prediction,\n","                        'ground_truth': ground_truth,\n","                        'chunk_analyses': chunk_analyses,\n","                        'num_chunks': len(frame_chunks),\n","                        'avg_processing_time': np.mean(processing_times) if processing_times else 0,\n","                        'phases_used': agent.phases\n","                    }\n","\n","                    match = \"‚úì\" if prediction == ground_truth else \"‚úó\"\n","                    print(f\"‚Üí {match} {prediction}\")\n","\n","        print(f\"\\n‚úì Processed {len(self.results)} videos\")\n","        return dict(self.results)\n","\n","    def _extract_prediction(self, analyses: List[str]) -> str:\n","        \"\"\"Extract crime prediction from analyses\"\"\"\n","        if not analyses:\n","            return 'uncertain'\n","\n","        full_text = \" \".join(analyses).lower()\n","\n","        crime_keywords = ['crime', 'theft', 'assault', 'robbery', 'suspicious',\n","                         'incident', 'illegal', 'criminal', 'violence', 'shoplifting']\n","\n","        crime_count = sum(1 for keyword in crime_keywords if keyword in full_text)\n","        high_conf = any(word in full_text for word in ['high confidence', 'clearly', 'definitely'])\n","\n","        if crime_count >= 3 or (crime_count >= 2 and high_conf):\n","            return 'crime'\n","        elif 'normal' in full_text or 'no crime' in full_text:\n","            return 'normal'\n","        return 'uncertain'\n","\n","    def _get_ground_truth(self, crime_type: str) -> str:\n","        \"\"\"Get ground truth label\"\"\"\n","        normal_categories = ['normal', 'regular', 'ordinary', 'safe', 'benign']\n","        if any(cat in crime_type.lower() for cat in normal_categories):\n","            return 'normal'\n","        return 'crime'\n","\n","    def _calculate_metrics(self, predictions: List[str], ground_truths: List[str]) -> Dict:\n","        \"\"\"Calculate performance metrics\"\"\"\n","        uncertain_count = sum(1 for p in predictions if p == 'uncertain')\n","\n","        valid_pairs = [(p, g) for p, g in zip(predictions, ground_truths)\n","                      if p in ['crime', 'normal']]\n","\n","        if not valid_pairs:\n","            return {\n","                'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0,\n","                'tp': 0, 'fp': 0, 'tn': 0, 'fn': 0,\n","                'uncertain_count': uncertain_count\n","            }\n","\n","        predictions, ground_truths = zip(*valid_pairs)\n","\n","        tp = sum(1 for p, g in zip(predictions, ground_truths) if p == 'crime' and g == 'crime')\n","        fp = sum(1 for p, g in zip(predictions, ground_truths) if p == 'crime' and g == 'normal')\n","        tn = sum(1 for p, g in zip(predictions, ground_truths) if p == 'normal' and g == 'normal')\n","        fn = sum(1 for p, g in zip(predictions, ground_truths) if p == 'normal' and g == 'crime')\n","\n","        total = tp + fp + tn + fn\n","        accuracy = (tp + tn) / total if total > 0 else 0\n","        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","\n","        return {\n","            'accuracy': accuracy,\n","            'precision': precision,\n","            'recall': recall,\n","            'f1': f1,\n","            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,\n","            'uncertain_count': uncertain_count\n","        }\n","\n","    def generate_report(self):\n","        \"\"\"Generate comprehensive multi-model report\"\"\"\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"GENERATING MULTI-MODEL ABLATION REPORT\")\n","        print(\"=\"*80 + \"\\n\")\n","\n","        # Calculate metrics for each model and configuration\n","        all_metrics = {}\n","\n","        for model_name in self.models.keys():\n","            all_metrics[model_name] = {}\n","\n","            for config_name in ['Full ReAct', 'No Decision', 'No Observation', 'Only Thought']:\n","                predictions = []\n","                ground_truths = []\n","                processing_times = []\n","\n","                for video_key, models_results in self.results.items():\n","                    if model_name in models_results and config_name in models_results[model_name]:\n","                        result = models_results[model_name][config_name]\n","                        predictions.append(result['prediction'])\n","                        ground_truths.append(result['ground_truth'])\n","                        processing_times.append(result['avg_processing_time'])\n","\n","                metrics = self._calculate_metrics(predictions, ground_truths)\n","                metrics['avg_processing_time'] = np.mean(processing_times) if processing_times else 0\n","                all_metrics[model_name][config_name] = metrics\n","\n","        # Create summary table\n","        self._create_summary_table(all_metrics)\n","\n","        # Create visualizations\n","        self._create_visualizations(all_metrics)\n","\n","        # Create detailed analysis\n","        self._create_detailed_analysis(all_metrics)\n","\n","        # Save raw results\n","        results_file = os.path.join(SAVE_DIR, \"raw_results_all_models.json\")\n","        with open(results_file, 'w') as f:\n","            json.dump(dict(self.results), f, indent=2)\n","\n","        print(f\"\\n‚úì Report saved to: {SAVE_DIR}\")\n","\n","    def _create_summary_table(self, all_metrics: Dict):\n","        \"\"\"Create summary table\"\"\"\n","        rows = []\n","\n","        for model_name, configs in all_metrics.items():\n","            for config_name, metrics in configs.items():\n","                rows.append({\n","                    'Model': model_name.upper(),\n","                    'Configuration': config_name,\n","                    'Accuracy': f\"{metrics['accuracy']:.4f}\",\n","                    'Precision': f\"{metrics['precision']:.4f}\",\n","                    'Recall': f\"{metrics['recall']:.4f}\",\n","                    'F1': f\"{metrics['f1']:.4f}\",\n","                    'Avg Time (s)': f\"{metrics['avg_processing_time']:.2f}\",\n","                    'Uncertain': metrics['uncertain_count']\n","                })\n","\n","        df = pd.DataFrame(rows)\n","        summary_path = os.path.join(SAVE_DIR, \"summary_all_models.csv\")\n","        df.to_csv(summary_path, index=False)\n","\n","        print(f\"‚úì Summary table: {summary_path}\")\n","        print(\"\\nSummary:\")\n","        print(df.to_string(index=False))\n","\n","    def _create_visualizations(self, all_metrics: Dict):\n","        \"\"\"Create comparison visualizations\"\"\"\n","        fig, axes = plt.subplots(3, 3, figsize=(20, 16))\n","        fig.suptitle(f'Multi-Model ReAct Ablation Study\\nEvery {self.frame_skip}th Frame',\n","                    fontsize=18, fontweight='bold')\n","\n","        models = list(all_metrics.keys())\n","        configs = ['Full ReAct', 'No Decision', 'No Observation', 'Only Thought']\n","        colors = {'gemini': '#4285F4', 'gpt': '#10A37F', 'claude': '#6B46C1'}\n","\n","        # Row 1: F1 Score Comparison\n","        for idx, model in enumerate(models):\n","            ax = axes[0, idx]\n","            f1_scores = [all_metrics[model][c]['f1'] for c in configs]\n","            bars = ax.bar(range(len(configs)), f1_scores, color=colors.get(model, '#999'),\n","                         alpha=0.8, edgecolor='black')\n","            ax.set_title(f'{model.upper()} - F1 Score', fontsize=14, fontweight='bold')\n","            ax.set_xticks(range(len(configs)))\n","            ax.set_xticklabels(configs, rotation=45, ha='right', fontsize=9)\n","            ax.set_ylim([0, 1.0])\n","            ax.set_ylabel('F1 Score', fontweight='bold')\n","            ax.grid(axis='y', alpha=0.3)\n","\n","            for bar in bars:\n","                height = bar.get_height()\n","                ax.text(bar.get_x() + bar.get_width()/2., height,\n","                       f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n","\n","        # Row 2: Processing Time Comparison\n","        for idx, model in enumerate(models):\n","            ax = axes[1, idx]\n","            times = [all_metrics[model][c]['avg_processing_time'] for c in configs]\n","            bars = ax.bar(range(len(configs)), times, color=colors.get(model, '#999'),\n","                         alpha=0.8, edgecolor='black')\n","            ax.set_title(f'{model.upper()} - Processing Time', fontsize=14, fontweight='bold')\n","            ax.set_xticks(range(len(configs)))\n","            ax.set_xticklabels(configs, rotation=45, ha='right', fontsize=9)\n","            ax.set_ylabel('Time (seconds)', fontweight='bold')\n","            ax.grid(axis='y', alpha=0.3)\n","\n","            for bar in bars:\n","                height = bar.get_height()\n","                ax.text(bar.get_x() + bar.get_width()/2., height,\n","                       f'{height:.1f}s', ha='center', va='bottom', fontsize=9)\n","\n","        # Row 3: Phase Impact Comparison\n","        for idx, model in enumerate(models):\n","            ax = axes[2, idx]\n","            baseline_f1 = all_metrics[model]['Full ReAct']['f1']\n","            impacts = {\n","                'Decision': baseline_f1 - all_metrics[model]['No Decision']['f1'],\n","                'Observation': baseline_f1 - all_metrics[model]['No Observation']['f1'],\n","                'Both': baseline_f1 - all_metrics[model]['Only Thought']['f1']\n","            }\n","\n","            phases = list(impacts.keys())\n","            values = list(impacts.values())\n","            bars = ax.bar(phases, values, color=['#e74c3c', '#3498db', '#9b59b6'],\n","                         alpha=0.8, edgecolor='black')\n","            ax.set_title(f'{model.upper()} - Phase Impact', fontsize=14, fontweight='bold')\n","            ax.set_ylabel('F1 Impact (drop)', fontweight='bold')\n","            ax.axhline(y=0, color='black', linestyle='--', linewidth=1)\n","            ax.grid(axis='y', alpha=0.3)\n","\n","            for bar in bars:\n","                height = bar.get_height()\n","                ax.text(bar.get_x() + bar.get_width()/2., height,\n","                       f'{height:.3f}', ha='center',\n","                       va='bottom' if height > 0 else 'top', fontsize=10)\n","\n","        plt.tight_layout()\n","        viz_path = os.path.join(SAVE_DIR, \"multi_model_comparison.png\")\n","        plt.savefig(viz_path, dpi=300, bbox_inches='tight')\n","        plt.close()\n","\n","        print(f\"‚úì Visualizations: {viz_path}\")\n","\n","    def _create_detailed_analysis(self, all_metrics: Dict):\n","        \"\"\"Create detailed text analysis\"\"\"\n","        report_path = os.path.join(SAVE_DIR, \"detailed_analysis_all_models.txt\")\n","\n","        with open(report_path, 'w') as f:\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(\"MULTI-MODEL REACT ABLATION STUDY - DETAILED ANALYSIS\\n\")\n","            f.write(f\"Frame Sampling: Every {self.frame_skip}th frame\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","            f.write(f\"Models Tested: {', '.join([m.upper() for m in all_metrics.keys()])}\\n\")\n","            f.write(f\"Videos Analyzed: {len(self.results)}\\n\\n\")\n","\n","            # Overall findings\n","            f.write(\"-\"*80 + \"\\n\")\n","            f.write(\"OVERALL FINDINGS\\n\")\n","            f.write(\"-\"*80 + \"\\n\\n\")\n","\n","            # Find best model and configuration\n","            best_f1 = 0\n","            best_model = None\n","            best_config = None\n","\n","            for model_name, configs in all_metrics.items():\n","                for config_name, metrics in configs.items():\n","                    if metrics['f1'] > best_f1:\n","                        best_f1 = metrics['f1']\n","                        best_model = model_name\n","                        best_config = config_name\n","\n","            f.write(f\"üèÜ BEST OVERALL: {best_model.upper()} - {best_config}\\n\")\n","            f.write(f\"   F1 Score: {best_f1:.4f}\\n\\n\")\n","\n","            # Per-model analysis\n","            f.write(\"-\"*80 + \"\\n\")\n","            f.write(\"PER-MODEL ANALYSIS\\n\")\n","            f.write(\"-\"*80 + \"\\n\\n\")\n","\n","            for model_name, configs in all_metrics.items():\n","                f.write(f\"\\n{model_name.upper()}:\\n\")\n","                f.write(\"-\" * 40 + \"\\n\")\n","\n","                baseline_f1 = configs['Full ReAct']['f1']\n","                decision_impact = baseline_f1 - configs['No Decision']['f1']\n","                observation_impact = baseline_f1 - configs['No Observation']['f1']\n","\n","                f.write(f\"  Best Configuration: \")\n","                best_config_f1 = max(configs.items(), key=lambda x: x[1]['f1'])\n","                f.write(f\"{best_config_f1[0]} (F1={best_config_f1[1]['f1']:.4f})\\n\\n\")\n","\n","                f.write(f\"  Phase Importance:\\n\")\n","                f.write(f\"    Decision Impact:    {decision_impact:+.4f}\\n\")\n","                f.write(f\"    Observation Impact: {observation_impact:+.4f}\\n\\n\")\n","\n","                f.write(f\"  Processing Efficiency:\\n\")\n","                for config_name, metrics in sorted(configs.items(),\n","                                                   key=lambda x: x[1]['avg_processing_time']):\n","                    f.write(f\"    {config_name:20s}: {metrics['avg_processing_time']:.2f}s\\n\")\n","\n","                f.write(\"\\n\")\n","\n","            # Comparative insights\n","            f.write(\"-\"*80 + \"\\n\")\n","            f.write(\"COMPARATIVE INSIGHTS\\n\")\n","            f.write(\"-\"*80 + \"\\n\\n\")\n","\n","            f.write(\"Which model benefits most from each phase?\\n\\n\")\n","\n","            for phase in ['Decision', 'Observation']:\n","                impacts = {}\n","                for model_name, configs in all_metrics.items():\n","                    baseline = configs['Full ReAct']['f1']\n","                    if phase == 'Decision':\n","                        ablated = configs['No Decision']['f1']\n","                    else:\n","                        ablated = configs['No Observation']['f1']\n","                    impacts[model_name] = baseline - ablated\n","\n","                most_dependent = max(impacts.items(), key=lambda x: abs(x[1]))\n","                f.write(f\"{phase} Phase:\\n\")\n","                f.write(f\"  Most dependent: {most_dependent[0].upper()} (impact: {most_dependent[1]:+.4f})\\n\")\n","                f.write(f\"  All impacts: {', '.join([f'{m.upper()}={v:+.3f}' for m, v in impacts.items()])}\\n\\n\")\n","\n","            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","            f.write(\"END OF REPORT\\n\")\n","            f.write(\"=\"*80 + \"\\n\")\n","\n","        print(f\"‚úì Detailed analysis: {report_path}\")\n","\n","\n","def load_api_keys(keys_dir: str) -> Dict[str, str]:\n","    \"\"\"Load API keys for all models\"\"\"\n","    print(\"\\n=== LOADING API KEYS ===\")\n","\n","    api_keys = {}\n","    key_files = {\n","        'gemini': 'Gemini.txt',\n","        'gpt': 'chatgpt.txt',\n","        'claude': 'claude.txt'\n","    }\n","\n","    for model_name, filename in key_files.items():\n","        filepath = os.path.join(keys_dir, filename)\n","        try:\n","            with open(filepath, 'r') as f:\n","                key = f.read().strip()\n","                if key:\n","                    api_keys[model_name] = key\n","                    print(f\"‚úì {model_name.upper()}: Loaded\")\n","                else:\n","                    print(f\"‚úó {model_name.upper()}: Empty file\")\n","        except Exception as e:\n","            print(f\"‚úó {model_name.upper()}: {str(e)}\")\n","\n","    print(f\"\\nLoaded {len(api_keys)}/{len(key_files)} API keys\\n\")\n","    return api_keys\n","\n","\n","def main():\n","    \"\"\"Main execution\"\"\"\n","    print(\"\\n\" + \"‚ïî\" + \"=\"*78 + \"‚ïó\")\n","    print(\"‚ïë\" + \" \"*15 + \"MULTI-MODEL REACT ABLATION STUDY\" + \" \"*31 + \"‚ïë\")\n","    print(\"‚ïë\" + \" \"*10 + \"Testing Gemini, GPT-4, and Claude with Every 90th Frame\" + \" \"*13 + \"‚ïë\")\n","    print(\"‚ïö\" + \"=\"*78 + \"‚ïù\\n\")\n","\n","    # Load API keys\n","    api_keys = load_api_keys(API_KEYS_DIR)\n","\n","    if not api_keys:\n","        print(\"‚úó No API keys loaded. Exiting.\")\n","        return {}, None\n","\n","    # Verify data directory\n","    if not os.path.exists(DATA_DIR):\n","        print(f\"‚úó Data directory not found: {DATA_DIR}\")\n","        return {}, None\n","\n","    print(f\"‚úì Data directory: {DATA_DIR}\")\n","\n","    # Initialize study\n","    study = MultiModelAblationStudy(\n","        api_keys=api_keys,\n","        data_path=DATA_DIR,\n","        frame_skip=FRAME_SKIP\n","    )\n","\n","    # Run study\n","    print(f\"\\nüöÄ Starting multi-model ablation study...\")\n","    results = study.run_study(max_videos=5)  # Set to None for all videos\n","\n","    if not results:\n","        print(\"\\n‚ö† No results generated\")\n","        return {}, None\n","\n","    # Generate report\n","    study.generate_report()\n","\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"‚úì MULTI-MODEL ABLATION STUDY COMPLETED\")\n","    print(\"=\"*80)\n","    print(f\"\\nüìÅ Results: {SAVE_DIR}/\")\n","    print(\"\\nGenerated files:\")\n","    print(\"  ‚Ä¢ summary_all_models.csv - Metrics for all models\")\n","    print(\"  ‚Ä¢ multi_model_comparison.png - Visual comparison\")\n","    print(\"  ‚Ä¢ detailed_analysis_all_models.txt - Complete analysis\")\n","    print(\"  ‚Ä¢ raw_results_all_models.json - Raw data\")\n","    print(\"\\n\" + \"=\"*80 + \"\\n\")\n","\n","    return results, study\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpqaF03OQTp3","executionInfo":{"status":"ok","timestamp":1762202075900,"user_tz":300,"elapsed":1038810,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"bca68c6f-32fa-4f92-83f2-7505d54e6f33"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","‚ïî==============================================================================‚ïó\n","‚ïë               MULTI-MODEL REACT ABLATION STUDY                               ‚ïë\n","‚ïë          Testing Gemini, GPT-4, and Claude with Every 90th Frame             ‚ïë\n","‚ïö==============================================================================‚ïù\n","\n","\n","=== LOADING API KEYS ===\n","‚úì GEMINI: Loaded\n","‚úì GPT: Loaded\n","‚úì CLAUDE: Loaded\n","\n","Loaded 3/3 API keys\n","\n","‚úì Data directory: /content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\n","Results will be saved to: /content/drive/MyDrive/multi_model_ablation_results\n","\n","üöÄ Starting multi-model ablation study...\n","\n","================================================================================\n","MULTI-MODEL REACT ABLATION STUDY\n","Testing 3 models √ó 4 configurations\n","Processing every 90th frame\n","================================================================================\n","\n","\n","=== DISCOVERING VIDEOS ===\n","Scanning: /content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\n","Found 11 crime types: ['Shoplifting', 'Fighting', 'Shooting', 'Stealing', 'Explosion', 'Arson', 'Vandalism', 'Abuse', 'Robbery', 'Burglary', 'Assault']\n","  Shoplifting: 2 videos\n","  Fighting: 2 videos\n","  Shooting: 2 videos\n","  Stealing: 2 videos\n","  Explosion: 2 videos\n","  Arson: 2 videos\n","  Vandalism: 2 videos\n","  Abuse: 2 videos\n","  Robbery: 2 videos\n","  Burglary: 2 videos\n","  Assault: 2 videos\n","Total videos: 22\n","‚ö† Processing 5 videos for testing\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rVideos:   0%|          | 0/5 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","--- Shoplifting_Shoplifting003_x264 ---\n","Crime type: Shoplifting\n","  Loaded 11 frames\n","\n","  Model: GEMINI\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: GPT\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: CLAUDE\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought "]},{"output_type":"stream","name":"stderr","text":["\rVideos:  20%|‚ñà‚ñà        | 1/5 [05:29<21:56, 329.22s/it]"]},{"output_type":"stream","name":"stdout","text":["‚Üí ‚úì crime\n","\n","--- Shoplifting_Shoplifting004_x264 ---\n","Crime type: Shoplifting\n","  Loaded 8 frames\n","\n","  Model: GEMINI\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: GPT\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úó uncertain\n","    Config: No Observation ‚Üí ‚úó uncertain\n","    Config: Only Thought ‚Üí ‚úó uncertain\n","\n","  Model: CLAUDE\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úó normal\n","    Config: No Observation ‚Üí ‚úó normal\n","    Config: Only Thought "]},{"output_type":"stream","name":"stderr","text":["\rVideos:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [08:45<12:33, 251.09s/it]"]},{"output_type":"stream","name":"stdout","text":["‚Üí ‚úì crime\n","\n","--- Fighting_Fighting003_x264 ---\n","Crime type: Fighting\n","  Loaded 3 frames\n","\n","  Model: GEMINI\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úó normal\n","\n","  Model: GPT\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úó uncertain\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: CLAUDE\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úó normal\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought "]},{"output_type":"stream","name":"stderr","text":["\rVideos:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [11:42<07:14, 217.23s/it]"]},{"output_type":"stream","name":"stdout","text":["‚Üí ‚úì crime\n","\n","--- Fighting_Fighting016_x264 ---\n","Crime type: Fighting\n","  Loaded 3 frames\n","\n","  Model: GEMINI\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: GPT\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: CLAUDE\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought "]},{"output_type":"stream","name":"stderr","text":["\rVideos:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [14:37<03:20, 200.44s/it]"]},{"output_type":"stream","name":"stdout","text":["‚Üí ‚úì crime\n","\n","--- Shooting_Shooting005_x264 ---\n","Crime type: Shooting\n","  Loaded 2 frames\n","\n","  Model: GEMINI\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: GPT\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought ‚Üí ‚úì crime\n","\n","  Model: CLAUDE\n","    Config: Full ReAct ‚Üí ‚úì crime\n","    Config: No Decision ‚Üí ‚úì crime\n","    Config: No Observation ‚Üí ‚úì crime\n","    Config: Only Thought "]},{"output_type":"stream","name":"stderr","text":["Videos: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [17:14<00:00, 206.93s/it]"]},{"output_type":"stream","name":"stdout","text":["‚Üí ‚úì crime\n","\n","‚úì Processed 5 videos\n","\n","================================================================================\n","GENERATING MULTI-MODEL ABLATION REPORT\n","================================================================================\n","\n","‚úì Summary table: /content/drive/MyDrive/multi_model_ablation_results/summary_all_models.csv\n","\n","Summary:\n"," Model  Configuration Accuracy Precision Recall     F1 Avg Time (s)  Uncertain\n","GEMINI     Full ReAct   1.0000    1.0000 1.0000 1.0000         7.18          0\n","GEMINI    No Decision   1.0000    1.0000 1.0000 1.0000         7.87          0\n","GEMINI No Observation   1.0000    1.0000 1.0000 1.0000         7.08          0\n","GEMINI   Only Thought   0.8000    1.0000 0.8000 0.8889         4.32          0\n","   GPT     Full ReAct   1.0000    1.0000 1.0000 1.0000        15.34          0\n","   GPT    No Decision   1.0000    1.0000 1.0000 1.0000        13.11          2\n","   GPT No Observation   1.0000    1.0000 1.0000 1.0000        13.79          1\n","   GPT   Only Thought   1.0000    1.0000 1.0000 1.0000        14.33          1\n","CLAUDE     Full ReAct   1.0000    1.0000 1.0000 1.0000        18.98          0\n","CLAUDE    No Decision   0.6000    1.0000 0.6000 0.7500        17.05          0\n","CLAUDE No Observation   0.8000    1.0000 0.8000 0.8889        14.98          0\n","CLAUDE   Only Thought   1.0000    1.0000 1.0000 1.0000        15.12          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["‚úì Visualizations: /content/drive/MyDrive/multi_model_ablation_results/multi_model_comparison.png\n","‚úì Detailed analysis: /content/drive/MyDrive/multi_model_ablation_results/detailed_analysis_all_models.txt\n","\n","‚úì Report saved to: /content/drive/MyDrive/multi_model_ablation_results\n","\n","================================================================================\n","‚úì MULTI-MODEL ABLATION STUDY COMPLETED\n","================================================================================\n","\n","üìÅ Results: /content/drive/MyDrive/multi_model_ablation_results/\n","\n","Generated files:\n","  ‚Ä¢ summary_all_models.csv - Metrics for all models\n","  ‚Ä¢ multi_model_comparison.png - Visual comparison\n","  ‚Ä¢ detailed_analysis_all_models.txt - Complete analysis\n","  ‚Ä¢ raw_results_all_models.json - Raw data\n","\n","================================================================================\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"7Rd494MLXbXu"},"execution_count":null,"outputs":[]}]}