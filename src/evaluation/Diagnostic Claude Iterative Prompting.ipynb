{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNuIIPSI67Uyz1JKeaSqLlZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KO-yoC5gohYv","executionInfo":{"status":"ok","timestamp":1762205566686,"user_tz":300,"elapsed":27301,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"c299ec95-900f-4b25-e813-54fdae18433f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q anthropic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcIJOcbNpd9n","executionInfo":{"status":"ok","timestamp":1762205762323,"user_tz":300,"elapsed":6312,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"f1aeca6a-476e-4c2c-ef49-a06bfa244b86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/357.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jf5FO2X8od4B","executionInfo":{"status":"ok","timestamp":1762206040462,"user_tz":300,"elapsed":274284,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"d670d757-937c-4b10-825a-67e18bf78ade"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","╔==============================================================================╗\n","║               CLAUDE ITERATIVE DIAGNOSTIC ANALYSIS                           ║\n","║          Tracing Failure Modes & Error Compounding                           ║\n","╚==============================================================================╝\n","\n","Loading API key...\n","✓ API key loaded\n","\n","Testing Claude API...\n","✓ API connection successful\n","\n","Initializing components...\n","\n","=== DISCOVERING VIDEOS ===\n","Scanning: /content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\n","Found 11 crime types: ['Shoplifting', 'Fighting', 'Shooting', 'Stealing', 'Explosion', 'Arson', 'Vandalism', 'Abuse', 'Robbery', 'Burglary', 'Assault']\n","  Shoplifting: 2 videos\n","  Fighting: 2 videos\n","  Shooting: 2 videos\n","  Stealing: 2 videos\n","  Explosion: 2 videos\n","  Arson: 2 videos\n","  Vandalism: 2 videos\n","  Abuse: 2 videos\n","  Robbery: 2 videos\n","  Burglary: 2 videos\n","  Assault: 2 videos\n","Total videos: 22\n","\n","Processing up to 3 videos for diagnostic analysis...\n","\n","================================================================================\n","VIDEO: Shoplifting_Shoplifting003_x264\n","================================================================================\n","  Loaded 11 frames (every 90th)\n","\n","================================================================================\n","DIAGNOSTIC ANALYSIS: Shoplifting003_x264 (Shoplifting)\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (816 chars)\n","  Preview: I cannot and will not analyze these images to identify potential criminal activity or make determinations about whether crimes are occurring. \n","\n","Even t...\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (916 chars)\n","  Preview: I maintain my position from the previous analysis. I cannot and will not analyze these surveillance images to identify potential criminal activity, re...\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (892 chars)\n","  Preview: I understand this is presented as \"iteration 3\" of an analysis, but my position remains unchanged regardless of how the request is framed or numbered....\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (894 chars)\n","  Preview: I understand you're presenting this as a continuation of previous analysis, but my position remains consistent regardless of how the request is framed...\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (617 chars)\n","  Preview: I cannot analyze surveillance footage to identify criminal activity, describe potential suspects, or provide evidence assessments for legal proceeding...\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (951 chars)\n","  Preview: I understand you're asking me to refine a previous analysis, but I maintain the same position I stated in iteration 5. I cannot analyze surveillance f...\n","\n","================================================================================\n","ANALYZING ERROR PROPAGATION...\n","================================================================================\n","\n","Failure Mode: Contradiction Accumulation\n","Compounding Mechanism: Model changes its interpretation across iterations, contradicting previous claims. Each iteration builds on flawed premises from the previous iteration, compounding errors.\n","  ✗ Error processing Shoplifting_Shoplifting003_x264: Object of type set is not JSON serializable\n","\n","================================================================================\n","VIDEO: Shoplifting_Shoplifting004_x264\n","================================================================================\n","  Loaded 8 frames (every 90th)\n","\n","================================================================================\n","DIAGNOSTIC ANALYSIS: Shoplifting004_x264 (Shoplifting)\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (814 chars)\n","  Preview: I cannot and will not analyze these images to identify criminal activity or provide evidence that could be used to accuse individuals of crimes. \n","\n","Whi...\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1424 chars)\n","  Preview: After reviewing my previous analysis and examining these frames again, I maintain my original position and find no errors in my approach.\n","\n","**Refined A...\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1565 chars)\n","  Preview: **ITERATION 3 - Final Refined Analysis**\n","\n","After three iterations of careful examination, I maintain my cautious analytical approach while providing mo...\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (1775 chars)\n","  Preview: **ITERATION 4 - Final Refinement**\n","\n","After reviewing my previous three iterations and re-examining the footage with fresh perspective, I maintain my an...\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (2022 chars)\n","  Preview: **ITERATION 5 - Final Refinement**\n","\n","After reviewing my previous four iterations and conducting this fifth examination of the footage, I maintain my an...\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1753 chars)\n","  Preview: **ITERATION 6 - Final Refinement**\n","\n","After conducting this sixth comprehensive review of the same footage and examining my previous analytical iteratio...\n","\n","================================================================================\n","ANALYZING ERROR PROPAGATION...\n","================================================================================\n","\n","Failure Mode: Contradiction Accumulation\n","Compounding Mechanism: Model changes its interpretation across iterations, contradicting previous claims. Each iteration builds on flawed premises from the previous iteration, compounding errors.\n","  ✗ Error processing Shoplifting_Shoplifting004_x264: Object of type set is not JSON serializable\n","\n","================================================================================\n","VIDEO: Fighting_Fighting003_x264\n","================================================================================\n","  Loaded 3 frames (every 90th)\n","\n","================================================================================\n","DIAGNOSTIC ANALYSIS: Fighting003_x264 (Fighting)\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (1692 chars)\n","  Preview: ## ITERATION 1 - Initial Analysis\n","\n","**1. What crime is occurring?**\n","Based on the video frames, this appears to be an assault or battery incident occurr...\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1985 chars)\n","  Preview: ## ITERATION 2 - Refinement\n","\n","**Reviewing Previous Analysis:**\n","Upon re-examination of the frames, I need to correct and refine my initial assessment.\n","\n","...\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1906 chars)\n","  Preview: ## ITERATION 3 - Final Refinement\n","\n","**Reviewing Previous Analysis:**\n","After three careful examinations of these frames, I need to significantly revise m...\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (2052 chars)\n","  Preview: ## ITERATION 4 - Final Refinement\n","\n","**Reviewing My Previous Analysis:**\n","After reviewing my iteration 3 conclusion that \"no crime is occurring,\" I need ...\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (2036 chars)\n","  Preview: ## ITERATION 5 - Refinement\n","\n","**Reviewing My Previous Analysis:**\n","I need to critically examine my iteration 4 conclusion about a \"coordinated group ass...\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1931 chars)\n","  Preview: ## ITERATION 6 - Refinement\n","\n","**Reviewing My Previous Analysis:**\n","Looking back at my iteration 5 conclusion, I corrected my earlier over-interpretation...\n","\n","================================================================================\n","ANALYZING ERROR PROPAGATION...\n","================================================================================\n","\n","Failure Mode: Contradiction Accumulation\n","Compounding Mechanism: Model changes its interpretation across iterations, contradicting previous claims. Each iteration builds on flawed premises from the previous iteration, compounding errors.\n","  ✗ Error processing Fighting_Fighting003_x264: Object of type set is not JSON serializable\n","\n","================================================================================\n","GENERATING SUMMARY REPORT\n","================================================================================\n","\n","✓ Summary report saved: /content/drive/MyDrive/claude_iterative_diagnostic/diagnostic_summary_20251103_214040.txt\n","\n","================================================================================\n","DIAGNOSTIC ANALYSIS COMPLETE\n","================================================================================\n","\n","Generated files:\n","  • Detailed diagnostics: 0 files\n","  • Trace examples: 0 files\n","  • Summary report: 1 file\n","\n","All files saved to: /content/drive/MyDrive/claude_iterative_diagnostic/\n","\n","================================================================================\n","\n","FAILURE MODES FOUND:\n","\n","✓ Use the trace examples in your paper to address reviewer concern!\n","  Look for files: trace_example_*.txt\n"]}],"source":["\"\"\"\n","Diagnostic Claude Iterative Prompting - Trace Failure Modes\n","Addresses reviewer concern: \"Claude's iterative method drops to near zero.\n","Please add one example trace to illustrate the failure mode and what error\n","compounds across turns.\"\n","\n","This script:\n","1. Runs Claude's iterative method on crime videos (every 90th frame)\n","2. Captures detailed traces showing how errors compound\n","3. Identifies specific failure modes\n","4. Generates publication-ready examples\n","\"\"\"\n","\n","import os\n","import json\n","import base64\n","import time\n","from datetime import datetime\n","from collections import defaultdict\n","import anthropic\n","import re\n","from difflib import SequenceMatcher\n","\n","# Mount Google Drive\n","try:\n","    from google.colab import drive\n","    if not os.path.exists('/content/drive'):\n","        drive.mount('/content/drive')\n","        print(\"✓ Google Drive mounted\")\n","except:\n","    print(\"Drive mount skipped\")\n","\n","# Configuration\n","API_KEY_PATH = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/SAVE/FINAL-COMPLETED/API-KEYS/claude.txt\"\n","DATA_DIR = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\"\n","SAVE_DIR = \"/content/drive/MyDrive/claude_iterative_diagnostic\"\n","FRAME_SKIP = 90  # Every 90th frame\n","CHUNK_SIZE = 10\n","MAX_ITERATIONS = 6\n","\n","\n","class ClaudeIterativeDiagnostic:\n","    \"\"\"Diagnostic analyzer for Claude's iterative failure modes\"\"\"\n","\n","    def __init__(self, api_key):\n","        self.api_key = api_key\n","        self.model_name = \"claude-sonnet-4-20250514\"\n","        self.client = anthropic.Anthropic(api_key=api_key)\n","        self.save_dir = SAVE_DIR\n","        os.makedirs(self.save_dir, exist_ok=True)\n","\n","        # Core question\n","        self.core_question = \"\"\"Analyze these video frames for criminal activity:\n","1. What crime is occurring?\n","2. Who are the individuals involved (describe appearances)?\n","3. What specific evidence supports your conclusion?\n","4. What is your confidence level (HIGH/MEDIUM/LOW)?\"\"\"\n","\n","    def make_request(self, messages):\n","        \"\"\"Make Claude API request with error handling\"\"\"\n","        try:\n","            response = self.client.messages.create(\n","                model=self.model_name,\n","                max_tokens=4096,\n","                temperature=0.1,\n","                messages=messages\n","            )\n","            return response.content[0].text, None\n","        except Exception as e:\n","            return None, str(e)\n","\n","    def extract_key_claims(self, text):\n","        \"\"\"Extract specific factual claims from response\"\"\"\n","        claims = {\n","            'crime_type': None,\n","            'num_people': None,\n","            'actions': [],\n","            'objects': [],\n","            'location': None,\n","            'confidence': None\n","        }\n","\n","        text_lower = text.lower()\n","\n","        # Extract crime type\n","        crime_keywords = ['theft', 'robbery', 'assault', 'vandalism', 'shoplifting',\n","                         'burglary', 'fighting', 'shooting', 'arson', 'explosion']\n","        for crime in crime_keywords:\n","            if crime in text_lower:\n","                claims['crime_type'] = crime\n","                break\n","\n","        # Extract number of people\n","        people_patterns = [\n","            r'(\\d+)\\s+(?:people|individuals|persons|suspects)',\n","            r'(\\w+)\\s+(?:people|individuals|persons|suspects)',  # \"two people\", etc.\n","        ]\n","        for pattern in people_patterns:\n","            match = re.search(pattern, text_lower)\n","            if match:\n","                claims['num_people'] = match.group(1)\n","                break\n","\n","        # Extract actions\n","        action_keywords = ['walking', 'running', 'standing', 'picking', 'grabbing',\n","                          'throwing', 'hitting', 'taking', 'leaving', 'entering']\n","        for action in action_keywords:\n","            if action in text_lower:\n","                claims['actions'].append(action)\n","\n","        # Extract objects\n","        object_keywords = ['bag', 'item', 'merchandise', 'product', 'weapon',\n","                          'car', 'door', 'counter', 'shelf', 'cash']\n","        for obj in object_keywords:\n","            if obj in text_lower:\n","                claims['objects'].append(obj)\n","\n","        # Extract confidence\n","        if 'high confidence' in text_lower or 'very confident' in text_lower:\n","            claims['confidence'] = 'HIGH'\n","        elif 'low confidence' in text_lower or 'uncertain' in text_lower:\n","            claims['confidence'] = 'LOW'\n","        else:\n","            claims['confidence'] = 'MEDIUM'\n","\n","        return claims\n","\n","    def compare_claims(self, claims1, claims2):\n","        \"\"\"Compare two sets of claims to identify changes/contradictions\"\"\"\n","        changes = {\n","            'crime_changed': claims1['crime_type'] != claims2['crime_type'],\n","            'people_changed': claims1['num_people'] != claims2['num_people'],\n","            'actions_added': set(claims2['actions']) - set(claims1['actions']),\n","            'actions_removed': set(claims1['actions']) - set(claims2['actions']),\n","            'objects_added': set(claims2['objects']) - set(claims1['objects']),\n","            'objects_removed': set(claims1['objects']) - set(claims2['objects']),\n","            'confidence_changed': claims1['confidence'] != claims2['confidence']\n","        }\n","\n","        # Identify contradictions (not just additions)\n","        changes['has_contradiction'] = (\n","            changes['crime_changed'] or\n","            changes['people_changed'] or\n","            len(changes['actions_removed']) > 0 or\n","            len(changes['objects_removed']) > 0\n","        )\n","\n","        return changes\n","\n","    def calculate_text_similarity(self, text1, text2):\n","        \"\"\"Calculate similarity between two texts\"\"\"\n","        return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()\n","\n","    def analyze_error_propagation(self, iterations_data):\n","        \"\"\"Analyze how errors compound across iterations\"\"\"\n","        error_analysis = {\n","            'iterations': [],\n","            'error_patterns': [],\n","            'failure_mode': None,\n","            'compounding_mechanism': None\n","        }\n","\n","        previous_claims = None\n","        previous_text = None\n","        contradiction_count = 0\n","        confidence_trajectory = []\n","\n","        for i, (iter_key, iter_data) in enumerate(sorted(iterations_data.items())):\n","            iteration_num = i + 1\n","            response = iter_data['response']\n","\n","            # Extract claims\n","            current_claims = self.extract_key_claims(response)\n","            confidence_trajectory.append(current_claims['confidence'])\n","\n","            iteration_analysis = {\n","                'iteration': iteration_num,\n","                'response_length': len(response),\n","                'claims': current_claims,\n","                'similarity_to_previous': 0.0,\n","                'contradictions': None,\n","                'error_indicators': []\n","            }\n","\n","            if previous_claims and previous_text:\n","                # Calculate similarity\n","                similarity = self.calculate_text_similarity(previous_text, response)\n","                iteration_analysis['similarity_to_previous'] = similarity\n","\n","                # Identify contradictions\n","                changes = self.compare_claims(previous_claims, current_claims)\n","                iteration_analysis['contradictions'] = changes\n","\n","                if changes['has_contradiction']:\n","                    contradiction_count += 1\n","                    error_analysis['error_patterns'].append({\n","                        'iteration': iteration_num,\n","                        'type': 'contradiction',\n","                        'details': changes\n","                    })\n","\n","                # Detect error indicators\n","                if changes['crime_changed']:\n","                    iteration_analysis['error_indicators'].append(\n","                        f\"Crime type changed: {previous_claims['crime_type']} → {current_claims['crime_type']}\"\n","                    )\n","\n","                if changes['people_changed']:\n","                    iteration_analysis['error_indicators'].append(\n","                        f\"Number of people changed: {previous_claims['num_people']} → {current_claims['num_people']}\"\n","                    )\n","\n","                if changes['confidence_changed']:\n","                    iteration_analysis['error_indicators'].append(\n","                        f\"Confidence changed: {previous_claims['confidence']} → {current_claims['confidence']}\"\n","                    )\n","\n","                # Check for increasing uncertainty\n","                if (previous_claims['confidence'] in ['HIGH', 'MEDIUM'] and\n","                    current_claims['confidence'] == 'LOW'):\n","                    iteration_analysis['error_indicators'].append(\n","                        \"Confidence decreased (potential confusion)\"\n","                    )\n","\n","                # Check for hallucination (too many new details with low similarity)\n","                if similarity < 0.3 and (len(changes['actions_added']) > 3 or\n","                                        len(changes['objects_added']) > 3):\n","                    iteration_analysis['error_indicators'].append(\n","                        \"Potential hallucination: Many new details with low similarity to previous\"\n","                    )\n","\n","            error_analysis['iterations'].append(iteration_analysis)\n","            previous_claims = current_claims\n","            previous_text = response\n","\n","        # Identify failure mode\n","        if contradiction_count >= 2:\n","            error_analysis['failure_mode'] = \"Contradiction Accumulation\"\n","            error_analysis['compounding_mechanism'] = (\n","                \"Model changes its interpretation across iterations, \"\n","                \"contradicting previous claims. Each iteration builds on \"\n","                \"flawed premises from the previous iteration, compounding errors.\"\n","            )\n","        elif len(set(confidence_trajectory)) == 1 and confidence_trajectory[0] == 'LOW':\n","            error_analysis['failure_mode'] = \"Persistent Uncertainty\"\n","            error_analysis['compounding_mechanism'] = (\n","                \"Model remains uncertain throughout iterations, unable to \"\n","                \"refine its understanding. Repeated exposure doesn't help.\"\n","            )\n","        elif any('hallucination' in str(iter_data.get('error_indicators', []))\n","                for iter_data in error_analysis['iterations']):\n","            error_analysis['failure_mode'] = \"Hallucination Cascade\"\n","            error_analysis['compounding_mechanism'] = (\n","                \"Model generates increasingly detailed but unsupported claims \"\n","                \"across iterations, building elaborate narratives not grounded \"\n","                \"in the visual evidence.\"\n","            )\n","        else:\n","            error_analysis['failure_mode'] = \"Gradual Degradation\"\n","            error_analysis['compounding_mechanism'] = (\n","                \"Model's responses become less coherent or accurate over \"\n","                \"iterations without a clear single cause.\"\n","            )\n","\n","        return error_analysis\n","\n","    def generate_trace_example(self, iterations_data, error_analysis, video_id, crime_type):\n","        \"\"\"Generate publication-ready trace example\"\"\"\n","        trace = {\n","            'video_id': video_id,\n","            'crime_type': crime_type,\n","            'model': self.model_name,\n","            'failure_mode': error_analysis['failure_mode'],\n","            'compounding_mechanism': error_analysis['compounding_mechanism'],\n","            'trace_by_iteration': []\n","        }\n","\n","        for iter_analysis in error_analysis['iterations']:\n","            iteration_num = iter_analysis['iteration']\n","            iter_key = f\"iteration_{iteration_num}\"\n","\n","            if iter_key in iterations_data:\n","                iter_data = iterations_data[iter_key]\n","\n","                trace_entry = {\n","                    'iteration': iteration_num,\n","                    'prompt_type': 'initial' if iteration_num == 1 else 'refinement',\n","                    'response_preview': iter_data['response'][:300] + '...',\n","                    'key_claims': iter_analysis['claims'],\n","                    'similarity_to_previous': iter_analysis['similarity_to_previous'],\n","                    'error_indicators': iter_analysis['error_indicators'],\n","                    'contradictions': iter_analysis['contradictions']\n","                }\n","\n","                trace['trace_by_iteration'].append(trace_entry)\n","\n","        return trace\n","\n","    def process_video_with_diagnostics(self, frames_data, video_id, crime_type):\n","        \"\"\"Process video with full diagnostic tracking\"\"\"\n","        print(f\"\\n{'='*80}\")\n","        print(f\"DIAGNOSTIC ANALYSIS: {video_id} ({crime_type})\")\n","        print(f\"{'='*80}\")\n","\n","        iterations = {}\n","        previous_response = None\n","\n","        for iteration_num in range(1, MAX_ITERATIONS + 1):\n","            print(f\"\\n--- Iteration {iteration_num}/{MAX_ITERATIONS} ---\")\n","\n","            # Prepare frames (take subset for each iteration)\n","            frames_subset = frames_data[:CHUNK_SIZE]\n","\n","            # Build prompt\n","            if iteration_num == 1:\n","                prompt = f\"\"\"ITERATION {iteration_num} - Initial Analysis\n","\n","Analyzing {crime_type} video:\n","\n","{self.core_question}\n","\n","Be specific and detailed. State your confidence level.\"\"\"\n","            else:\n","                prompt = f\"\"\"ITERATION {iteration_num} - Refinement\n","\n","Previous analysis from iteration {iteration_num - 1}:\n","{previous_response[:500]}...\n","\n","Now analyze the SAME frames again with these instructions:\n","1. Review your previous analysis\n","2. Look for any errors or oversights\n","3. Refine your conclusions\n","4. Update your confidence level\n","\n","{self.core_question}\"\"\"\n","\n","            # Prepare message with images\n","            content = [{\"type\": \"text\", \"text\": prompt}]\n","            for frame in frames_subset:\n","                content.append({\n","                    \"type\": \"image\",\n","                    \"source\": {\n","                        \"type\": \"base64\",\n","                        \"media_type\": \"image/png\",\n","                        \"data\": frame\n","                    }\n","                })\n","\n","            messages = [{\"role\": \"user\", \"content\": content}]\n","\n","            # Make request\n","            response, error = self.make_request(messages)\n","\n","            if error:\n","                print(f\"  ✗ Error: {error}\")\n","                iterations[f\"iteration_{iteration_num}\"] = {\n","                    \"iteration\": iteration_num,\n","                    \"error\": error,\n","                    \"response\": None\n","                }\n","                break\n","\n","            print(f\"  ✓ Response received ({len(response)} chars)\")\n","            print(f\"  Preview: {response[:150]}...\")\n","\n","            # Store iteration data\n","            iterations[f\"iteration_{iteration_num}\"] = {\n","                \"iteration\": iteration_num,\n","                \"prompt\": prompt,\n","                \"response\": response,\n","                \"response_length\": len(response)\n","            }\n","\n","            previous_response = response\n","\n","            # Rate limiting\n","            if iteration_num < MAX_ITERATIONS:\n","                time.sleep(3)\n","\n","        # Analyze error propagation\n","        print(f\"\\n{'='*80}\")\n","        print(\"ANALYZING ERROR PROPAGATION...\")\n","        print(f\"{'='*80}\")\n","\n","        error_analysis = self.analyze_error_propagation(iterations)\n","\n","        print(f\"\\nFailure Mode: {error_analysis['failure_mode']}\")\n","        print(f\"Compounding Mechanism: {error_analysis['compounding_mechanism']}\")\n","\n","        # Generate trace example\n","        trace_example = self.generate_trace_example(\n","            iterations, error_analysis, video_id, crime_type\n","        )\n","\n","        # Save results\n","        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n","\n","        # Save detailed results\n","        detailed_file = os.path.join(\n","            self.save_dir,\n","            f\"diagnostic_{crime_type}_{video_id}_{timestamp}.json\"\n","        )\n","        with open(detailed_file, 'w') as f:\n","            json.dump({\n","                'video_id': video_id,\n","                'crime_type': crime_type,\n","                'iterations': iterations,\n","                'error_analysis': error_analysis,\n","                'trace_example': trace_example\n","            }, f, indent=2)\n","\n","        print(f\"\\n✓ Detailed results saved: {detailed_file}\")\n","\n","        # Generate publication-ready trace\n","        self.generate_publication_trace(trace_example, video_id, crime_type)\n","\n","        return trace_example, error_analysis\n","\n","    def generate_publication_trace(self, trace, video_id, crime_type):\n","        \"\"\"Generate publication-ready trace text file\"\"\"\n","        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n","        trace_file = os.path.join(\n","            self.save_dir,\n","            f\"trace_example_{crime_type}_{video_id}_{timestamp}.txt\"\n","        )\n","\n","        with open(trace_file, 'w') as f:\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(f\"CLAUDE ITERATIVE FAILURE MODE TRACE EXAMPLE\\n\")\n","            f.write(f\"Video: {video_id} ({crime_type})\\n\")\n","            f.write(f\"Model: {trace['model']}\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            f.write(f\"IDENTIFIED FAILURE MODE: {trace['failure_mode']}\\n\\n\")\n","\n","            f.write(\"COMPOUNDING MECHANISM:\\n\")\n","            f.write(f\"{trace['compounding_mechanism']}\\n\\n\")\n","\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(\"ITERATION-BY-ITERATION TRACE\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            for trace_entry in trace['trace_by_iteration']:\n","                f.write(f\"\\n{'─'*80}\\n\")\n","                f.write(f\"ITERATION {trace_entry['iteration']}\\n\")\n","                f.write(f\"{'─'*80}\\n\\n\")\n","\n","                f.write(f\"Response Preview:\\n{trace_entry['response_preview']}\\n\\n\")\n","\n","                f.write(\"Key Claims:\\n\")\n","                claims = trace_entry['key_claims']\n","                f.write(f\"  • Crime Type: {claims['crime_type']}\\n\")\n","                f.write(f\"  • Number of People: {claims['num_people']}\\n\")\n","                f.write(f\"  • Actions: {', '.join(claims['actions']) if claims['actions'] else 'None'}\\n\")\n","                f.write(f\"  • Objects: {', '.join(claims['objects']) if claims['objects'] else 'None'}\\n\")\n","                f.write(f\"  • Confidence: {claims['confidence']}\\n\\n\")\n","\n","                if trace_entry['iteration'] > 1:\n","                    f.write(f\"Similarity to Previous: {trace_entry['similarity_to_previous']:.3f}\\n\\n\")\n","\n","                    if trace_entry['error_indicators']:\n","                        f.write(\"⚠ ERROR INDICATORS:\\n\")\n","                        for indicator in trace_entry['error_indicators']:\n","                            f.write(f\"  • {indicator}\\n\")\n","                        f.write(\"\\n\")\n","\n","                    if trace_entry['contradictions']:\n","                        contras = trace_entry['contradictions']\n","                        if contras['has_contradiction']:\n","                            f.write(\"❌ CONTRADICTIONS DETECTED:\\n\")\n","                            if contras['crime_changed']:\n","                                f.write(\"  • Crime type changed\\n\")\n","                            if contras['people_changed']:\n","                                f.write(\"  • Number of people changed\\n\")\n","                            if contras['actions_removed']:\n","                                f.write(f\"  • Actions removed: {', '.join(contras['actions_removed'])}\\n\")\n","                            if contras['objects_removed']:\n","                                f.write(f\"  • Objects removed: {', '.join(contras['objects_removed'])}\\n\")\n","                            f.write(\"\\n\")\n","\n","            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","            f.write(\"ANALYSIS SUMMARY\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            f.write(\"This trace illustrates how errors compound in Claude's iterative approach:\\n\\n\")\n","\n","            if trace['failure_mode'] == \"Contradiction Accumulation\":\n","                f.write(\"1. Initial response makes claims about the video\\n\")\n","                f.write(\"2. Subsequent iterations change these claims\\n\")\n","                f.write(\"3. Contradictions accumulate, confusing the model\\n\")\n","                f.write(\"4. Later iterations build on flawed premises\\n\")\n","                f.write(\"5. Performance degrades as errors compound\\n\\n\")\n","                f.write(\"HOW TO AVOID:\\n\")\n","                f.write(\"• Use fresh context for each iteration (don't feed back previous responses)\\n\")\n","                f.write(\"• Implement consistency checks across iterations\\n\")\n","                f.write(\"• Stop iteration when contradictions are detected\\n\")\n","\n","            elif trace['failure_mode'] == \"Hallucination Cascade\":\n","                f.write(\"1. Initial response makes reasonable observations\\n\")\n","                f.write(\"2. Subsequent iterations add unsupported details\\n\")\n","                f.write(\"3. Model generates increasingly elaborate narratives\\n\")\n","                f.write(\"4. Later claims become detached from visual evidence\\n\")\n","                f.write(\"5. Confidence remains high despite hallucinations\\n\\n\")\n","                f.write(\"HOW TO AVOID:\\n\")\n","                f.write(\"• Ground each iteration in visual evidence\\n\")\n","                f.write(\"• Penalize addition of unsupported details\\n\")\n","                f.write(\"• Require explicit evidence for each claim\\n\")\n","\n","            elif trace['failure_mode'] == \"Persistent Uncertainty\":\n","                f.write(\"1. Initial response expresses uncertainty\\n\")\n","                f.write(\"2. Subsequent iterations fail to resolve uncertainty\\n\")\n","                f.write(\"3. Model cannot refine understanding through iteration\\n\")\n","                f.write(\"4. Repeated exposure doesn't help\\n\")\n","                f.write(\"5. Resources wasted on unproductive iterations\\n\\n\")\n","                f.write(\"HOW TO AVOID:\\n\")\n","                f.write(\"• Detect early uncertainty and skip iteration\\n\")\n","                f.write(\"• Use different prompting strategy for ambiguous cases\\n\")\n","                f.write(\"• Provide more context or different frame samples\\n\")\n","\n","            else:\n","                f.write(\"Multiple error patterns detected. See detailed trace above.\\n\\n\")\n","                f.write(\"HOW TO AVOID:\\n\")\n","                f.write(\"• Monitor response quality across iterations\\n\")\n","                f.write(\"• Implement early stopping when degradation detected\\n\")\n","                f.write(\"• Use ensemble approaches instead of iteration\\n\")\n","\n","        print(f\"✓ Publication trace saved: {trace_file}\")\n","\n","\n","class VideoLoader:\n","    \"\"\"Load and sample video frames\"\"\"\n","\n","    def __init__(self, data_dir, frame_skip=90):\n","        self.data_dir = data_dir\n","        self.frame_skip = frame_skip\n","\n","    def discover_videos(self):\n","        \"\"\"Discover all videos\"\"\"\n","        print(f\"\\n=== DISCOVERING VIDEOS ===\")\n","        print(f\"Scanning: {self.data_dir}\")\n","\n","        all_videos = {}\n","\n","        try:\n","            crime_types = [d for d in os.listdir(self.data_dir)\n","                          if os.path.isdir(os.path.join(self.data_dir, d))]\n","\n","            print(f\"Found {len(crime_types)} crime types: {crime_types}\")\n","\n","            for crime_type in crime_types:\n","                crime_dir = os.path.join(self.data_dir, crime_type)\n","                all_files = os.listdir(crime_dir)\n","\n","                video_groups = defaultdict(list)\n","\n","                for filename in all_files:\n","                    if not any(filename.lower().endswith(ext)\n","                             for ext in ['.png', '.jpg', '.jpeg', '.bmp']):\n","                        continue\n","\n","                    video_id = self._extract_video_id(filename)\n","                    if video_id:\n","                        video_groups[video_id].append(filename)\n","\n","                print(f\"  {crime_type}: {len(video_groups)} videos\")\n","\n","                for video_id, frames in video_groups.items():\n","                    all_videos[f\"{crime_type}_{video_id}\"] = {\n","                        'crime_type': crime_type,\n","                        'video_id': video_id,\n","                        'frames': sorted(frames, key=self._extract_frame_number),\n","                        'crime_dir': crime_dir\n","                    }\n","\n","        except Exception as e:\n","            print(f\"Error: {str(e)}\")\n","\n","        print(f\"Total videos: {len(all_videos)}\")\n","        return all_videos\n","\n","    def _extract_video_id(self, filename):\n","        \"\"\"Extract video ID from filename\"\"\"\n","        import re\n","        name_without_ext = os.path.splitext(filename)[0]\n","\n","        if '_frame_' in name_without_ext:\n","            return name_without_ext.split('_frame_')[0]\n","\n","        parts = name_without_ext.split('_')\n","        if len(parts) >= 2:\n","            try:\n","                int(parts[-1])\n","                return '_'.join(parts[:-1])\n","            except ValueError:\n","                pass\n","\n","        video_id = re.sub(r'_?\\d+$', '', name_without_ext)\n","        if video_id and video_id != name_without_ext:\n","            return video_id\n","\n","        return name_without_ext\n","\n","    def _extract_frame_number(self, filename):\n","        \"\"\"Extract frame number for sorting\"\"\"\n","        import re\n","        try:\n","            if '_frame_' in filename:\n","                parts = filename.split('_frame_')\n","                if len(parts) > 1:\n","                    return int(parts[1].split('.')[0])\n","            numbers = re.findall(r'\\d+', filename)\n","            if numbers:\n","                return int(numbers[-1])\n","        except:\n","            pass\n","        return 0\n","\n","    def load_video_frames(self, video_info):\n","        \"\"\"Load frames (every Nth frame)\"\"\"\n","        crime_dir = video_info['crime_dir']\n","        all_frames = video_info['frames']\n","\n","        selected_frames = all_frames[::self.frame_skip]\n","\n","        frames_data = []\n","        for frame_file in selected_frames:\n","            frame_path = os.path.join(crime_dir, frame_file)\n","            try:\n","                with open(frame_path, 'rb') as f:\n","                    frame_data = base64.b64encode(f.read()).decode('utf-8')\n","                    frames_data.append(frame_data)\n","            except Exception as e:\n","                print(f\"  Error loading {frame_file}: {str(e)}\")\n","\n","        print(f\"  Loaded {len(frames_data)} frames (every {self.frame_skip}th)\")\n","        return frames_data\n","\n","\n","def main():\n","    \"\"\"Main execution\"\"\"\n","    print(\"\\n\" + \"╔\" + \"=\"*78 + \"╗\")\n","    print(\"║\" + \" \"*15 + \"CLAUDE ITERATIVE DIAGNOSTIC ANALYSIS\" + \" \"*27 + \"║\")\n","    print(\"║\" + \" \"*10 + \"Tracing Failure Modes & Error Compounding\" + \" \"*27 + \"║\")\n","    print(\"╚\" + \"=\"*78 + \"╝\\n\")\n","\n","    # Load API key\n","    print(\"Loading API key...\")\n","    try:\n","        with open(API_KEY_PATH, 'r') as f:\n","            api_key = f.read().strip()\n","        if not api_key:\n","            print(\"✗ API key file is empty\")\n","            return\n","        print(\"✓ API key loaded\")\n","    except Exception as e:\n","        print(f\"✗ Error loading API key: {str(e)}\")\n","        return\n","\n","    # Test API\n","    print(\"\\nTesting Claude API...\")\n","    try:\n","        client = anthropic.Anthropic(api_key=api_key)\n","        response = client.messages.create(\n","            model=\"claude-sonnet-4-20250514\",\n","            max_tokens=50,\n","            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n","        )\n","        print(\"✓ API connection successful\")\n","    except Exception as e:\n","        print(f\"✗ API test failed: {str(e)}\")\n","        return\n","\n","    # Initialize components\n","    print(\"\\nInitializing components...\")\n","    diagnostic = ClaudeIterativeDiagnostic(api_key)\n","    loader = VideoLoader(DATA_DIR, frame_skip=FRAME_SKIP)\n","\n","    # Discover videos\n","    all_videos = loader.discover_videos()\n","\n","    if not all_videos:\n","        print(\"✗ No videos found\")\n","        return\n","\n","    # Process videos (limit to 3 for demonstration)\n","    print(f\"\\nProcessing up to 3 videos for diagnostic analysis...\")\n","\n","    results = []\n","    for video_key, video_info in list(all_videos.items())[:3]:\n","        print(f\"\\n{'='*80}\")\n","        print(f\"VIDEO: {video_key}\")\n","        print(f\"{'='*80}\")\n","\n","        try:\n","            # Load frames\n","            frames_data = loader.load_video_frames(video_info)\n","\n","            if not frames_data:\n","                print(\"  ✗ No frames loaded\")\n","                continue\n","\n","            # Run diagnostic analysis\n","            trace, error_analysis = diagnostic.process_video_with_diagnostics(\n","                frames_data,\n","                video_info['video_id'],\n","                video_info['crime_type']\n","            )\n","\n","            results.append({\n","                'video_key': video_key,\n","                'trace': trace,\n","                'error_analysis': error_analysis\n","            })\n","\n","        except Exception as e:\n","            print(f\"  ✗ Error processing {video_key}: {str(e)}\")\n","\n","    # Generate summary report\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"GENERATING SUMMARY REPORT\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    summary_file = os.path.join(SAVE_DIR, f\"diagnostic_summary_{time.strftime('%Y%m%d_%H%M%S')}.txt\")\n","\n","    with open(summary_file, 'w') as f:\n","        f.write(\"=\"*80 + \"\\n\")\n","        f.write(\"CLAUDE ITERATIVE PROMPTING - DIAGNOSTIC SUMMARY\\n\")\n","        f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        f.write(f\"Videos Analyzed: {len(results)}\\n\")\n","        f.write(f\"Frame Sampling: Every {FRAME_SKIP}th frame\\n\")\n","        f.write(f\"Max Iterations: {MAX_ITERATIONS}\\n\")\n","        f.write(f\"Model: claude-sonnet-4-20250514\\n\\n\")\n","\n","        f.write(\"FAILURE MODES IDENTIFIED:\\n\\n\")\n","\n","        failure_mode_counts = defaultdict(int)\n","        for result in results:\n","            failure_mode = result['trace']['failure_mode']\n","            failure_mode_counts[failure_mode] += 1\n","\n","            f.write(f\"Video: {result['video_key']}\\n\")\n","            f.write(f\"  Failure Mode: {failure_mode}\\n\")\n","            f.write(f\"  Mechanism: {result['trace']['compounding_mechanism']}\\n\\n\")\n","\n","        f.write(\"\\n\" + \"-\"*80 + \"\\n\")\n","        f.write(\"FAILURE MODE DISTRIBUTION:\\n\")\n","        f.write(\"-\"*80 + \"\\n\\n\")\n","\n","        for mode, count in failure_mode_counts.items():\n","            pct = (count / len(results)) * 100\n","            f.write(f\"{mode}: {count} ({pct:.1f}%)\\n\")\n","\n","        f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\")\n","        f.write(\"RECOMMENDATIONS FOR AVOIDING THESE FAILURES\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        f.write(\"1. DETECT EARLY FAILURE SIGNALS\\n\")\n","        f.write(\"   • Monitor for contradictions between iterations\\n\")\n","        f.write(\"   • Track confidence trajectory (decreasing = warning sign)\\n\")\n","        f.write(\"   • Check similarity scores (too low = drift, too high = stuck)\\n\\n\")\n","\n","        f.write(\"2. IMPLEMENT SAFEGUARDS\\n\")\n","        f.write(\"   • Stop iteration when contradictions detected\\n\")\n","        f.write(\"   • Limit iterations to 3-4 maximum\\n\")\n","        f.write(\"   • Require evidence grounding for new claims\\n\\n\")\n","\n","        f.write(\"3. ALTERNATIVE APPROACHES\\n\")\n","        f.write(\"   • Use ensemble methods instead of iteration\\n\")\n","        f.write(\"   • Try different frame samples rather than iterating\\n\")\n","        f.write(\"   • Consider multi-turn conversation instead of refinement\\n\\n\")\n","\n","        f.write(\"4. FOR YOUR PAPER\\n\")\n","        f.write(\"   • Include one trace example (see individual trace files)\\n\")\n","        f.write(\"   • Explain the specific failure mode observed\\n\")\n","        f.write(\"   • Show how errors compound across iterations\\n\")\n","        f.write(\"   • Provide concrete recommendations for avoidance\\n\")\n","\n","    print(f\"✓ Summary report saved: {summary_file}\")\n","\n","    # Final summary\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"DIAGNOSTIC ANALYSIS COMPLETE\")\n","    print(\"=\"*80)\n","    print(f\"\\nGenerated files:\")\n","    print(f\"  • Detailed diagnostics: {len(results)} files\")\n","    print(f\"  • Trace examples: {len(results)} files\")\n","    print(f\"  • Summary report: 1 file\")\n","    print(f\"\\nAll files saved to: {SAVE_DIR}/\")\n","    print(\"\\n\" + \"=\"*80)\n","\n","    # Print failure modes summary\n","    print(\"\\nFAILURE MODES FOUND:\")\n","    for mode, count in failure_mode_counts.items():\n","        pct = (count / len(results)) * 100\n","        print(f\"  • {mode}: {count} ({pct:.1f}%)\")\n","\n","    print(\"\\n✓ Use the trace examples in your paper to address reviewer concern!\")\n","    print(\"  Look for files: trace_example_*.txt\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}