{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1740rrojbZ0zRzl-cnQ_Tvh2C3OBOZhIi","timestamp":1762207505454}],"authorship_tag":"ABX9TyNhsVlPsIT74pzjFbSmXMjF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KO-yoC5gohYv","executionInfo":{"status":"ok","timestamp":1762207974128,"user_tz":300,"elapsed":49247,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"9e0f6d06-d9c4-427d-80f5-4f623778fa5c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q anthropic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcIJOcbNpd9n","executionInfo":{"status":"ok","timestamp":1762208014897,"user_tz":300,"elapsed":8129,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"b05755a0-2566-4f3f-8596-ee5159eb725b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/357.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m348.2/357.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jf5FO2X8od4B","executionInfo":{"status":"ok","timestamp":1762208500708,"user_tz":300,"elapsed":482165,"user":{"displayName":"opeyemi adeniran","userId":"06352095503427961436"}},"outputId":"82ce4bd1-96ff-461d-adba-adc51ab555bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","╔==============================================================================╗\n","║            SIMILARITY-BASED STOPPING DIAGNOSTIC ANALYSIS                     ║\n","║          Explicit Metrics, Thresholds & Failure Cases                       ║\n","╚==============================================================================╝\n","\n","STOPPING RULE CONFIGURATION:\n","  • Similarity Metric: SequenceMatcher\n","  • Similarity Threshold: 0.85\n","  • Embedding Model: Claude API embeddings\n","  • Minimum Iterations: 2\n","  • Maximum Iterations: 6\n","\n","Loading API key...\n","✓ API key loaded\n","\n","Testing Claude API...\n","✓ API connection successful\n","\n","Initializing components...\n","\n","=== DISCOVERING VIDEOS ===\n","Scanning: /content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\n","Found 11 crime types: ['Shoplifting', 'Fighting', 'Shooting', 'Stealing', 'Explosion', 'Arson', 'Vandalism', 'Abuse', 'Robbery', 'Burglary', 'Assault']\n","  Shoplifting: 2 videos\n","  Fighting: 2 videos\n","  Shooting: 2 videos\n","  Stealing: 2 videos\n","  Explosion: 2 videos\n","  Arson: 2 videos\n","  Vandalism: 2 videos\n","  Abuse: 2 videos\n","  Robbery: 2 videos\n","  Burglary: 2 videos\n","  Assault: 2 videos\n","Total videos: 22\n","\n","Processing up to 5 videos for similarity-based stopping analysis...\n","\n","================================================================================\n","VIDEO: Shoplifting_Shoplifting003_x264\n","================================================================================\n","  Loaded 11 frames (every 90th)\n","\n","================================================================================\n","SIMILARITY-BASED STOPPING ANALYSIS: Shoplifting003_x264 (Shoplifting)\n","================================================================================\n","Similarity Metric: SequenceMatcher\n","Threshold: 0.85\n","Min Iterations: 2\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (876 chars)\n","  Quality Score: 0.700\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1211 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.096\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1159 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.040\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (1120 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.577\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (1068 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.855\n","  Should stop: True (threshold: 0.85)\n","\n","  ⚠ STOPPING RULE TRIGGERED at iteration 5\n","     Similarity 0.855 >= threshold 0.85\n","\n","  Note: Continuing iterations for diagnostic comparison\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1110 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.884\n","  Should stop: True (threshold: 0.85)\n","\n","  ⚠ STOPPING RULE TRIGGERED at iteration 6\n","     Similarity 0.884 >= threshold 0.85\n","\n","  Note: Continuing iterations for diagnostic comparison\n","\n","================================================================================\n","ANALYZING STOPPING RULE PERFORMANCE...\n","================================================================================\n","\n","✓ Stopping rule performed correctly\n","\n","✓ Detailed results saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/stopping_analysis_Shoplifting_Shoplifting003_x264_20251103_221501.json\n","\n","================================================================================\n","VIDEO: Shoplifting_Shoplifting004_x264\n","================================================================================\n","  Loaded 8 frames (every 90th)\n","\n","================================================================================\n","SIMILARITY-BASED STOPPING ANALYSIS: Shoplifting004_x264 (Shoplifting)\n","================================================================================\n","Similarity Metric: SequenceMatcher\n","Threshold: 0.85\n","Min Iterations: 2\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (860 chars)\n","  Quality Score: 0.850\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1424 chars)\n","  Quality Score: 0.600\n","  Similarity to previous: 0.017\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1799 chars)\n","  Quality Score: 1.000\n","  Similarity to previous: 0.071\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (1831 chars)\n","  Quality Score: 0.850\n","  Similarity to previous: 0.127\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (1665 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.100\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1740 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.296\n","  Should stop: False (threshold: 0.85)\n","\n","================================================================================\n","ANALYZING STOPPING RULE PERFORMANCE...\n","================================================================================\n","\n","⚠ STOPPING RULE FAILURE DETECTED\n","  Type: Type B: No Convergence\n","  Description: Never reached similarity threshold (0.85). Maximum similarity achieved: 0.296. Responses oscillate or drift without converging.\n","\n","✓ Detailed results saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/stopping_analysis_Shoplifting_Shoplifting004_x264_20251103_221738.json\n","✓ Failure trace saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/FAILURE_TRACE_Type_B__No_Convergence_Shoplifting_Shoplifting004_x264_20251103_221738.txt\n","\n","================================================================================\n","VIDEO: Fighting_Fighting003_x264\n","================================================================================\n","  Loaded 3 frames (every 90th)\n","\n","================================================================================\n","SIMILARITY-BASED STOPPING ANALYSIS: Fighting003_x264 (Fighting)\n","================================================================================\n","Similarity Metric: SequenceMatcher\n","Threshold: 0.85\n","Min Iterations: 2\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (1577 chars)\n","  Quality Score: 0.850\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1894 chars)\n","  Quality Score: 0.850\n","  Similarity to previous: 0.153\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1723 chars)\n","  Quality Score: 0.800\n","  Similarity to previous: 0.194\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (1348 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.334\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (1806 chars)\n","  Quality Score: 0.850\n","  Similarity to previous: 0.298\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1856 chars)\n","  Quality Score: 0.850\n","  Similarity to previous: 0.286\n","  Should stop: False (threshold: 0.85)\n","\n","================================================================================\n","ANALYZING STOPPING RULE PERFORMANCE...\n","================================================================================\n","\n","⚠ STOPPING RULE FAILURE DETECTED\n","  Type: Type B: No Convergence\n","  Description: Never reached similarity threshold (0.85). Maximum similarity achieved: 0.334. Responses oscillate or drift without converging.\n","\n","✓ Detailed results saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/stopping_analysis_Fighting_Fighting003_x264_20251103_221856.json\n","✓ Failure trace saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/FAILURE_TRACE_Type_B__No_Convergence_Fighting_Fighting003_x264_20251103_221856.txt\n","\n","================================================================================\n","VIDEO: Fighting_Fighting016_x264\n","================================================================================\n","  Loaded 3 frames (every 90th)\n","\n","================================================================================\n","SIMILARITY-BASED STOPPING ANALYSIS: Fighting016_x264 (Fighting)\n","================================================================================\n","Similarity Metric: SequenceMatcher\n","Threshold: 0.85\n","Min Iterations: 2\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (1640 chars)\n","  Quality Score: 1.000\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1908 chars)\n","  Quality Score: 0.950\n","  Similarity to previous: 0.113\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (2073 chars)\n","  Quality Score: 0.850\n","  Similarity to previous: 0.164\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (2111 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.145\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (2267 chars)\n","  Quality Score: 0.800\n","  Similarity to previous: 0.092\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (2047 chars)\n","  Quality Score: 0.800\n","  Similarity to previous: 0.051\n","  Should stop: False (threshold: 0.85)\n","\n","================================================================================\n","ANALYZING STOPPING RULE PERFORMANCE...\n","================================================================================\n","\n","⚠ STOPPING RULE FAILURE DETECTED\n","  Type: Type B: No Convergence\n","  Description: Never reached similarity threshold (0.85). Maximum similarity achieved: 0.164. Responses oscillate or drift without converging.\n","\n","✓ Detailed results saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/stopping_analysis_Fighting_Fighting016_x264_20251103_222024.json\n","✓ Failure trace saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/FAILURE_TRACE_Type_B__No_Convergence_Fighting_Fighting016_x264_20251103_222024.txt\n","\n","================================================================================\n","VIDEO: Shooting_Shooting005_x264\n","================================================================================\n","  Loaded 2 frames (every 90th)\n","\n","================================================================================\n","SIMILARITY-BASED STOPPING ANALYSIS: Shooting005_x264 (Shooting)\n","================================================================================\n","Similarity Metric: SequenceMatcher\n","Threshold: 0.85\n","Min Iterations: 2\n","================================================================================\n","\n","--- Iteration 1/6 ---\n","  ✓ Response received (1362 chars)\n","  Quality Score: 0.600\n","\n","--- Iteration 2/6 ---\n","  ✓ Response received (1915 chars)\n","  Quality Score: 0.650\n","  Similarity to previous: 0.224\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 3/6 ---\n","  ✓ Response received (1955 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.176\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 4/6 ---\n","  ✓ Response received (1812 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.137\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 5/6 ---\n","  ✓ Response received (1979 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.332\n","  Should stop: False (threshold: 0.85)\n","\n","--- Iteration 6/6 ---\n","  ✓ Response received (1844 chars)\n","  Quality Score: 0.700\n","  Similarity to previous: 0.471\n","  Should stop: False (threshold: 0.85)\n","\n","================================================================================\n","ANALYZING STOPPING RULE PERFORMANCE...\n","================================================================================\n","\n","⚠ STOPPING RULE FAILURE DETECTED\n","  Type: Type B: No Convergence\n","  Description: Never reached similarity threshold (0.85). Maximum similarity achieved: 0.471. Responses oscillate or drift without converging.\n","\n","✓ Detailed results saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/stopping_analysis_Shooting_Shooting005_x264_20251103_222140.json\n","✓ Failure trace saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/FAILURE_TRACE_Type_B__No_Convergence_Shooting_Shooting005_x264_20251103_222140.txt\n","\n","================================================================================\n","GENERATING SUMMARY REPORT\n","================================================================================\n","\n","✓ Summary report saved: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/similarity_stopping_summary_20251103_222140.txt\n","\n","================================================================================\n","ANALYSIS COMPLETE\n","================================================================================\n","\n","Results:\n","  • Videos analyzed: 5\n","  • Failure cases: 4 (80.0%)\n","\n","Generated files:\n","  • Detailed analyses: 5 files\n","  • Failure traces: 4 files\n","  • Summary report: 1 file\n","\n","All files saved to: /content/drive/MyDrive/claude_similarity_stopping_diagnostic/\n","\n","⚠ FAILURE CASES DETECTED:\n","  • Type B: No Convergence: 4 (100.0%)\n","\n","✓ Use FAILURE_TRACE_*.txt files in your paper!\n","  These provide concrete examples addressing the reviewer's concern.\n","\n","================================================================================\n"]}],"source":["\"\"\"\n","Diagnostic Claude Iterative Prompting - Similarity-Based Stopping Analysis\n","Addresses reviewer concern: \"The iterative method uses a 'similarity-based stopping'\n","rule. Name the similarity metric, threshold, and embedding model. Report failure\n","cases for Claude with concrete traces.\"\n","\n","This script:\n","1. Implements explicit similarity-based stopping with named metrics\n","2. Tests multiple similarity metrics (SequenceMatcher, cosine similarity with embeddings)\n","3. Documents threshold values and stopping criteria\n","4. Identifies and traces failure cases where stopping rule fails\n","5. Generates publication-ready failure case examples\n","\"\"\"\n","\n","import os\n","import json\n","import base64\n","import time\n","from datetime import datetime\n","from collections import defaultdict\n","import anthropic\n","import re\n","from difflib import SequenceMatcher\n","import numpy as np\n","\n","# Mount Google Drive\n","try:\n","    from google.colab import drive\n","    if not os.path.exists('/content/drive'):\n","        drive.mount('/content/drive')\n","        print(\"✓ Google Drive mounted\")\n","except:\n","    print(\"Drive mount skipped\")\n","\n","# Configuration\n","API_KEY_PATH = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/SAVE/FINAL-COMPLETED/API-KEYS/claude.txt\"\n","DATA_DIR = \"/content/drive/Shareddrives/DR KOFI RESEARCH/RESEARCH/COMPLETED/PROMPTS/crime-data\"\n","SAVE_DIR = \"/content/drive/MyDrive/claude_similarity_stopping_diagnostic\"\n","FRAME_SKIP = 90  # Every 90th frame\n","CHUNK_SIZE = 10\n","MAX_ITERATIONS = 6\n","\n","# SIMILARITY-BASED STOPPING PARAMETERS (EXPLICITLY DOCUMENTED)\n","SIMILARITY_METRIC = \"SequenceMatcher\"  # Options: \"SequenceMatcher\", \"Cosine\"\n","SIMILARITY_THRESHOLD = 0.85  # Stop if similarity >= this value\n","MIN_ITERATIONS = 2  # Minimum iterations before stopping rule applies\n","EMBEDDING_MODEL = \"Claude API embeddings\"  # For cosine similarity option\n","\n","\n","class SimilarityBasedStopping:\n","    \"\"\"\n","    Implements similarity-based stopping criteria for iterative prompting.\n","\n","    STOPPING RULE:\n","    - Metric: SequenceMatcher ratio (Ratcliff/Obershelp algorithm)\n","    - Threshold: 0.85 (85% similarity)\n","    - Min iterations: 2\n","    - Stop when: similarity(response_i, response_i-1) >= 0.85\n","\n","    FAILURE MODES:\n","    - Type A: Stops too early (converges to wrong answer)\n","    - Type B: Never stops (oscillates or drifts)\n","    - Type C: Stops after degradation (quality decreased before stopping)\n","    \"\"\"\n","\n","    def __init__(self, metric=\"SequenceMatcher\", threshold=0.85, min_iterations=2):\n","        self.metric = metric\n","        self.threshold = threshold\n","        self.min_iterations = min_iterations\n","        self.client = None  # For embeddings if using cosine similarity\n","\n","    def calculate_similarity(self, text1, text2):\n","        \"\"\"\n","        Calculate similarity between two texts using specified metric.\n","\n","        Returns:\n","            float: Similarity score between 0 and 1\n","        \"\"\"\n","        if self.metric == \"SequenceMatcher\":\n","            # Ratcliff/Obershelp algorithm from difflib\n","            # Computes similarity as 2*M/T where M is number of matching characters\n","            # and T is total number of characters in both strings\n","            return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()\n","\n","        elif self.metric == \"Cosine\":\n","            # Cosine similarity using Claude embeddings\n","            if not self.client:\n","                raise ValueError(\"Client not initialized for embedding-based similarity\")\n","            return self._cosine_similarity_embeddings(text1, text2)\n","\n","        else:\n","            raise ValueError(f\"Unknown similarity metric: {self.metric}\")\n","\n","    def _cosine_similarity_embeddings(self, text1, text2):\n","        \"\"\"\n","        Calculate cosine similarity using Claude API embeddings.\n","        Note: This requires embedding capability from Claude API\n","        \"\"\"\n","        try:\n","            # Get embeddings for both texts\n","            # Note: You may need to adjust this based on actual Claude embedding API\n","            embedding1 = self._get_embedding(text1)\n","            embedding2 = self._get_embedding(text2)\n","\n","            # Calculate cosine similarity\n","            dot_product = np.dot(embedding1, embedding2)\n","            norm1 = np.linalg.norm(embedding1)\n","            norm2 = np.linalg.norm(embedding2)\n","\n","            return dot_product / (norm1 * norm2)\n","        except Exception as e:\n","            print(f\"Warning: Embedding-based similarity failed, falling back to SequenceMatcher: {e}\")\n","            return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()\n","\n","    def _get_embedding(self, text):\n","        \"\"\"\n","        Get embedding vector for text using Claude API.\n","        Note: Placeholder - implement based on actual API\n","        \"\"\"\n","        # For now, use simple character frequency as pseudo-embedding\n","        # In production, use actual Claude embeddings or sentence-transformers\n","        vocab_size = 256\n","        embedding = np.zeros(vocab_size)\n","        for char in text[:1000]:  # Limit to first 1000 chars\n","            embedding[ord(char) % vocab_size] += 1\n","        return embedding / (np.linalg.norm(embedding) + 1e-10)\n","\n","    def should_stop(self, iteration_num, similarity_score):\n","        \"\"\"\n","        Determine if iteration should stop based on similarity.\n","\n","        Args:\n","            iteration_num: Current iteration number\n","            similarity_score: Similarity between current and previous response\n","\n","        Returns:\n","            bool: True if should stop, False otherwise\n","        \"\"\"\n","        if iteration_num < self.min_iterations:\n","            return False\n","\n","        return similarity_score >= self.threshold\n","\n","    def analyze_stopping_failure(self, similarity_history, quality_history):\n","        \"\"\"\n","        Analyze if stopping rule failed and classify failure type.\n","\n","        Args:\n","            similarity_history: List of similarity scores across iterations\n","            quality_history: List of quality indicators across iterations\n","\n","        Returns:\n","            dict: Failure analysis\n","        \"\"\"\n","        failure_analysis = {\n","            'failed': False,\n","            'failure_type': None,\n","            'description': None,\n","            'supporting_evidence': {}\n","        }\n","\n","        # Type A: Stopped too early (high similarity but low quality)\n","        if len(similarity_history) >= 1:\n","            first_stop_iter = None\n","            for i, sim in enumerate(similarity_history):\n","                if sim >= self.threshold and i >= self.min_iterations - 1:\n","                    first_stop_iter = i + 2  # Convert to 1-indexed iteration\n","                    break\n","\n","            if first_stop_iter and first_stop_iter <= 3:\n","                # Check if quality was still improving after stopping point\n","                if quality_history and len(quality_history) > first_stop_iter:\n","                    early_quality = quality_history[first_stop_iter - 1]\n","                    later_quality = quality_history[-1]\n","\n","                    if later_quality > early_quality + 0.1:  # Significant improvement missed\n","                        failure_analysis['failed'] = True\n","                        failure_analysis['failure_type'] = 'Type A: Premature Convergence'\n","                        failure_analysis['description'] = (\n","                            f\"Stopped at iteration {first_stop_iter} due to high similarity \"\n","                            f\"({similarity_history[first_stop_iter-2]:.3f}), but quality continued \"\n","                            f\"to improve in later iterations ({early_quality:.3f} → {later_quality:.3f})\"\n","                        )\n","                        failure_analysis['supporting_evidence'] = {\n","                            'stop_iteration': first_stop_iter,\n","                            'similarity_at_stop': similarity_history[first_stop_iter - 2],\n","                            'quality_at_stop': early_quality,\n","                            'final_quality': later_quality,\n","                            'missed_improvement': later_quality - early_quality\n","                        }\n","\n","        # Type B: Never stopped (low similarity throughout)\n","        if not failure_analysis['failed']:\n","            max_sim = max(similarity_history) if similarity_history else 0\n","            if max_sim < self.threshold:\n","                failure_analysis['failed'] = True\n","                failure_analysis['failure_type'] = 'Type B: No Convergence'\n","                failure_analysis['description'] = (\n","                    f\"Never reached similarity threshold ({self.threshold}). \"\n","                    f\"Maximum similarity achieved: {max_sim:.3f}. \"\n","                    f\"Responses oscillate or drift without converging.\"\n","                )\n","                failure_analysis['supporting_evidence'] = {\n","                    'max_similarity': max_sim,\n","                    'threshold': self.threshold,\n","                    'similarity_history': similarity_history,\n","                    'variance': np.var(similarity_history) if similarity_history else 0\n","                }\n","\n","        # Type C: Stopped after degradation (quality decreased before stopping)\n","        if not failure_analysis['failed'] and len(quality_history) >= 3:\n","            # Find if quality peaked and then decreased before stopping\n","            peak_quality = max(quality_history)\n","            peak_iter = quality_history.index(peak_quality) + 1\n","\n","            final_quality = quality_history[-1]\n","            if peak_quality > final_quality + 0.15 and peak_iter < len(quality_history):\n","                failure_analysis['failed'] = True\n","                failure_analysis['failure_type'] = 'Type C: Post-Degradation Stop'\n","                failure_analysis['description'] = (\n","                    f\"Quality peaked at iteration {peak_iter} ({peak_quality:.3f}) \"\n","                    f\"but continued iterating until quality degraded ({final_quality:.3f}). \"\n","                    f\"Should have stopped at peak.\"\n","                )\n","                failure_analysis['supporting_evidence'] = {\n","                    'peak_iteration': peak_iter,\n","                    'peak_quality': peak_quality,\n","                    'final_quality': final_quality,\n","                    'degradation': peak_quality - final_quality\n","                }\n","\n","        return failure_analysis\n","\n","\n","class ClaudeIterativeDiagnostic:\n","    \"\"\"Diagnostic analyzer for Claude's iterative method with similarity-based stopping\"\"\"\n","\n","    def __init__(self, api_key):\n","        self.api_key = api_key\n","        self.model_name = \"claude-sonnet-4-20250514\"\n","        self.client = anthropic.Anthropic(api_key=api_key)\n","        self.save_dir = SAVE_DIR\n","        os.makedirs(self.save_dir, exist_ok=True)\n","\n","        # Initialize similarity-based stopping\n","        self.stopping_rule = SimilarityBasedStopping(\n","            metric=SIMILARITY_METRIC,\n","            threshold=SIMILARITY_THRESHOLD,\n","            min_iterations=MIN_ITERATIONS\n","        )\n","        self.stopping_rule.client = self.client\n","\n","        # Core question\n","        self.core_question = \"\"\"Analyze these video frames for criminal activity:\n","1. What crime is occurring?\n","2. Who are the individuals involved (describe appearances)?\n","3. What specific evidence supports your conclusion?\n","4. What is your confidence level (HIGH/MEDIUM/LOW)?\"\"\"\n","\n","    def make_request(self, messages):\n","        \"\"\"Make Claude API request with error handling\"\"\"\n","        try:\n","            response = self.client.messages.create(\n","                model=self.model_name,\n","                max_tokens=4096,\n","                temperature=0.1,\n","                messages=messages\n","            )\n","            return response.content[0].text, None\n","        except Exception as e:\n","            return None, str(e)\n","\n","    def extract_key_claims(self, text):\n","        \"\"\"Extract specific factual claims from response\"\"\"\n","        claims = {\n","            'crime_type': None,\n","            'num_people': None,\n","            'actions': [],\n","            'objects': [],\n","            'location': None,\n","            'confidence': None\n","        }\n","\n","        text_lower = text.lower()\n","\n","        # Extract crime type\n","        crime_keywords = ['theft', 'robbery', 'assault', 'vandalism', 'shoplifting',\n","                         'burglary', 'fighting', 'shooting', 'arson', 'explosion']\n","        for crime in crime_keywords:\n","            if crime in text_lower:\n","                claims['crime_type'] = crime\n","                break\n","\n","        # Extract number of people\n","        people_patterns = [\n","            r'(\\d+)\\s+(?:people|individuals|persons|suspects)',\n","            r'(\\w+)\\s+(?:people|individuals|persons|suspects)',\n","        ]\n","        for pattern in people_patterns:\n","            match = re.search(pattern, text_lower)\n","            if match:\n","                claims['num_people'] = match.group(1)\n","                break\n","\n","        # Extract actions\n","        action_keywords = ['walking', 'running', 'standing', 'picking', 'grabbing',\n","                          'throwing', 'hitting', 'taking', 'leaving', 'entering']\n","        for action in action_keywords:\n","            if action in text_lower:\n","                claims['actions'].append(action)\n","\n","        # Extract objects\n","        object_keywords = ['bag', 'item', 'merchandise', 'product', 'weapon',\n","                          'car', 'door', 'counter', 'shelf', 'cash']\n","        for obj in object_keywords:\n","            if obj in text_lower:\n","                claims['objects'].append(obj)\n","\n","        # Extract confidence\n","        if 'high confidence' in text_lower or 'very confident' in text_lower:\n","            claims['confidence'] = 'HIGH'\n","        elif 'low confidence' in text_lower or 'uncertain' in text_lower:\n","            claims['confidence'] = 'LOW'\n","        else:\n","            claims['confidence'] = 'MEDIUM'\n","\n","        return claims\n","\n","    def assess_response_quality(self, response, claims):\n","        \"\"\"\n","        Assess quality of response (0-1 scale).\n","        Higher score = better quality (specific, confident, coherent)\n","        \"\"\"\n","        quality_score = 0.5  # Base score\n","\n","        # Specificity: Has crime type and details\n","        if claims['crime_type']:\n","            quality_score += 0.15\n","        if claims['num_people']:\n","            quality_score += 0.1\n","        if len(claims['actions']) >= 2:\n","            quality_score += 0.1\n","        if len(claims['objects']) >= 1:\n","            quality_score += 0.1\n","\n","        # Confidence\n","        if claims['confidence'] == 'HIGH':\n","            quality_score += 0.15\n","        elif claims['confidence'] == 'LOW':\n","            quality_score -= 0.1\n","\n","        # Length (not too short, not too long)\n","        length = len(response)\n","        if 200 <= length <= 1000:\n","            quality_score += 0.1\n","        elif length < 100:\n","            quality_score -= 0.15\n","\n","        # Coherence: Check for contradiction indicators\n","        contradiction_words = ['however', 'although', 'unclear', 'uncertain', 'cannot determine']\n","        contradiction_count = sum(1 for word in contradiction_words if word in response.lower())\n","        quality_score -= (contradiction_count * 0.05)\n","\n","        return max(0.0, min(1.0, quality_score))\n","\n","    def process_video_with_similarity_stopping(self, frames_data, video_id, crime_type):\n","        \"\"\"Process video with similarity-based stopping rule\"\"\"\n","        print(f\"\\n{'='*80}\")\n","        print(f\"SIMILARITY-BASED STOPPING ANALYSIS: {video_id} ({crime_type})\")\n","        print(f\"{'='*80}\")\n","        print(f\"Similarity Metric: {self.stopping_rule.metric}\")\n","        print(f\"Threshold: {self.stopping_rule.threshold}\")\n","        print(f\"Min Iterations: {self.stopping_rule.min_iterations}\")\n","        print(f\"{'='*80}\")\n","\n","        iterations = {}\n","        previous_response = None\n","        similarity_history = []\n","        quality_history = []\n","        stopped_early = False\n","        stop_iteration = None\n","\n","        for iteration_num in range(1, MAX_ITERATIONS + 1):\n","            print(f\"\\n--- Iteration {iteration_num}/{MAX_ITERATIONS} ---\")\n","\n","            # Prepare frames\n","            frames_subset = frames_data[:CHUNK_SIZE]\n","\n","            # Build prompt\n","            if iteration_num == 1:\n","                prompt = f\"\"\"ITERATION {iteration_num} - Initial Analysis\n","\n","Analyzing {crime_type} video:\n","\n","{self.core_question}\n","\n","Be specific and detailed. State your confidence level.\"\"\"\n","            else:\n","                prompt = f\"\"\"ITERATION {iteration_num} - Refinement\n","\n","Previous analysis from iteration {iteration_num - 1}:\n","{previous_response[:500]}...\n","\n","Now analyze the SAME frames again with these instructions:\n","1. Review your previous analysis\n","2. Look for any errors or oversights\n","3. Refine your conclusions\n","4. Update your confidence level\n","\n","{self.core_question}\"\"\"\n","\n","            # Prepare message with images\n","            content = [{\"type\": \"text\", \"text\": prompt}]\n","            for frame in frames_subset:\n","                content.append({\n","                    \"type\": \"image\",\n","                    \"source\": {\n","                        \"type\": \"base64\",\n","                        \"media_type\": \"image/png\",\n","                        \"data\": frame\n","                    }\n","                })\n","\n","            messages = [{\"role\": \"user\", \"content\": content}]\n","\n","            # Make request\n","            response, error = self.make_request(messages)\n","\n","            if error:\n","                print(f\"  ✗ Error: {error}\")\n","                iterations[f\"iteration_{iteration_num}\"] = {\n","                    \"iteration\": iteration_num,\n","                    \"error\": error,\n","                    \"response\": None\n","                }\n","                break\n","\n","            print(f\"  ✓ Response received ({len(response)} chars)\")\n","\n","            # Extract claims and assess quality\n","            claims = self.extract_key_claims(response)\n","            quality = self.assess_response_quality(response, claims)\n","            quality_history.append(quality)\n","\n","            print(f\"  Quality Score: {quality:.3f}\")\n","\n","            # Calculate similarity if not first iteration\n","            similarity = None\n","            if previous_response:\n","                similarity = self.stopping_rule.calculate_similarity(previous_response, response)\n","                similarity_history.append(similarity)\n","                print(f\"  Similarity to previous: {similarity:.3f}\")\n","\n","                # Check stopping rule\n","                should_stop = self.stopping_rule.should_stop(iteration_num, similarity)\n","                print(f\"  Should stop: {should_stop} (threshold: {self.stopping_rule.threshold})\")\n","\n","                if should_stop:\n","                    stopped_early = True\n","                    stop_iteration = iteration_num\n","                    print(f\"\\n  ⚠ STOPPING RULE TRIGGERED at iteration {iteration_num}\")\n","                    print(f\"     Similarity {similarity:.3f} >= threshold {self.stopping_rule.threshold}\")\n","\n","            # Store iteration data\n","            iterations[f\"iteration_{iteration_num}\"] = {\n","                \"iteration\": iteration_num,\n","                \"prompt\": prompt,\n","                \"response\": response,\n","                \"response_length\": len(response),\n","                \"claims\": claims,\n","                \"quality\": quality,\n","                \"similarity\": similarity\n","            }\n","\n","            previous_response = response\n","\n","            # Stop if rule triggered (but continue for diagnostic purposes)\n","            if stopped_early and iteration_num == stop_iteration:\n","                print(f\"\\n  Note: Continuing iterations for diagnostic comparison\")\n","\n","            # Rate limiting\n","            if iteration_num < MAX_ITERATIONS:\n","                time.sleep(3)\n","\n","        # Analyze stopping rule performance\n","        print(f\"\\n{'='*80}\")\n","        print(\"ANALYZING STOPPING RULE PERFORMANCE...\")\n","        print(f\"{'='*80}\")\n","\n","        stopping_analysis = {\n","            'metric': self.stopping_rule.metric,\n","            'threshold': self.stopping_rule.threshold,\n","            'min_iterations': self.stopping_rule.min_iterations,\n","            'stopped_early': stopped_early,\n","            'stop_iteration': stop_iteration,\n","            'total_iterations': len(iterations),\n","            'similarity_history': similarity_history,\n","            'quality_history': quality_history\n","        }\n","\n","        # Analyze failure modes\n","        failure_analysis = self.stopping_rule.analyze_stopping_failure(\n","            similarity_history, quality_history\n","        )\n","\n","        stopping_analysis['failure_analysis'] = failure_analysis\n","\n","        if failure_analysis['failed']:\n","            print(f\"\\n⚠ STOPPING RULE FAILURE DETECTED\")\n","            print(f\"  Type: {failure_analysis['failure_type']}\")\n","            print(f\"  Description: {failure_analysis['description']}\")\n","        else:\n","            print(f\"\\n✓ Stopping rule performed correctly\")\n","\n","        # Generate trace\n","        trace_example = self.generate_stopping_trace(\n","            iterations, stopping_analysis, video_id, crime_type\n","        )\n","\n","        # Save results\n","        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n","\n","        detailed_file = os.path.join(\n","            self.save_dir,\n","            f\"stopping_analysis_{crime_type}_{video_id}_{timestamp}.json\"\n","        )\n","        with open(detailed_file, 'w') as f:\n","            json.dump({\n","                'video_id': video_id,\n","                'crime_type': crime_type,\n","                'iterations': iterations,\n","                'stopping_analysis': stopping_analysis,\n","                'trace_example': trace_example\n","            }, f, indent=2)\n","\n","        print(f\"\\n✓ Detailed results saved: {detailed_file}\")\n","\n","        # Generate failure trace if applicable\n","        if failure_analysis['failed']:\n","            self.generate_failure_trace(trace_example, video_id, crime_type, failure_analysis)\n","\n","        return trace_example, stopping_analysis\n","\n","    def generate_stopping_trace(self, iterations, stopping_analysis, video_id, crime_type):\n","        \"\"\"Generate trace showing similarity-based stopping behavior\"\"\"\n","        trace = {\n","            'video_id': video_id,\n","            'crime_type': crime_type,\n","            'model': self.model_name,\n","            'stopping_rule': {\n","                'metric': stopping_analysis['metric'],\n","                'threshold': stopping_analysis['threshold'],\n","                'min_iterations': stopping_analysis['min_iterations']\n","            },\n","            'stopping_behavior': {\n","                'stopped_early': stopping_analysis['stopped_early'],\n","                'stop_iteration': stopping_analysis['stop_iteration'],\n","                'total_iterations': stopping_analysis['total_iterations']\n","            },\n","            'failure_analysis': stopping_analysis['failure_analysis'],\n","            'iterations': []\n","        }\n","\n","        for i in range(1, stopping_analysis['total_iterations'] + 1):\n","            iter_key = f\"iteration_{i}\"\n","            if iter_key in iterations:\n","                iter_data = iterations[iter_key]\n","\n","                trace_entry = {\n","                    'iteration': i,\n","                    'response_preview': iter_data['response'][:300] + '...',\n","                    'quality': iter_data['quality'],\n","                    'similarity': iter_data['similarity'],\n","                    'claims': iter_data['claims'],\n","                    'would_stop': False\n","                }\n","\n","                # Check if stopping rule would trigger\n","                if iter_data['similarity'] and i >= stopping_analysis['min_iterations']:\n","                    trace_entry['would_stop'] = (\n","                        iter_data['similarity'] >= stopping_analysis['threshold']\n","                    )\n","\n","                trace['iterations'].append(trace_entry)\n","\n","        return trace\n","\n","    def generate_failure_trace(self, trace, video_id, crime_type, failure_analysis):\n","        \"\"\"Generate publication-ready failure trace\"\"\"\n","        timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n","        trace_file = os.path.join(\n","            self.save_dir,\n","            f\"FAILURE_TRACE_{failure_analysis['failure_type'].replace(':', '_').replace(' ', '_')}_{crime_type}_{video_id}_{timestamp}.txt\"\n","        )\n","\n","        with open(trace_file, 'w') as f:\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(\"SIMILARITY-BASED STOPPING RULE FAILURE TRACE\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            f.write(f\"Video: {video_id} ({crime_type})\\n\")\n","            f.write(f\"Model: {trace['model']}\\n\\n\")\n","\n","            f.write(\"STOPPING RULE CONFIGURATION:\\n\")\n","            f.write(f\"  • Metric: {trace['stopping_rule']['metric']}\\n\")\n","            f.write(f\"  • Threshold: {trace['stopping_rule']['threshold']}\\n\")\n","            f.write(f\"  • Min Iterations: {trace['stopping_rule']['min_iterations']}\\n\\n\")\n","\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(f\"FAILURE TYPE: {failure_analysis['failure_type']}\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            f.write(\"FAILURE DESCRIPTION:\\n\")\n","            f.write(f\"{failure_analysis['description']}\\n\\n\")\n","\n","            f.write(\"SUPPORTING EVIDENCE:\\n\")\n","            for key, value in failure_analysis['supporting_evidence'].items():\n","                f.write(f\"  • {key}: {value}\\n\")\n","            f.write(\"\\n\")\n","\n","            f.write(\"=\"*80 + \"\\n\")\n","            f.write(\"ITERATION-BY-ITERATION TRACE\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            for trace_entry in trace['iterations']:\n","                f.write(f\"\\n{'─'*80}\\n\")\n","                f.write(f\"ITERATION {trace_entry['iteration']}\\n\")\n","                f.write(f\"{'─'*80}\\n\\n\")\n","\n","                f.write(f\"Quality Score: {trace_entry['quality']:.3f}\\n\")\n","                if trace_entry['similarity'] is not None:\n","                    f.write(f\"Similarity to Previous: {trace_entry['similarity']:.3f}\\n\")\n","                    f.write(f\"Would Stop: {trace_entry['would_stop']}\\n\")\n","                f.write(\"\\n\")\n","\n","                f.write(f\"Response Preview:\\n{trace_entry['response_preview']}\\n\\n\")\n","\n","                f.write(\"Key Claims:\\n\")\n","                claims = trace_entry['claims']\n","                f.write(f\"  • Crime Type: {claims['crime_type']}\\n\")\n","                f.write(f\"  • Number of People: {claims['num_people']}\\n\")\n","                f.write(f\"  • Confidence: {claims['confidence']}\\n\\n\")\n","\n","            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","            f.write(\"ANALYSIS & RECOMMENDATIONS\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            if failure_analysis['failure_type'] == 'Type A: Premature Convergence':\n","                f.write(\"PROBLEM: The stopping rule triggered too early, converging before\\n\")\n","                f.write(\"the model reached its best answer. High similarity was achieved, but\\n\")\n","                f.write(\"quality continued to improve in subsequent iterations.\\n\\n\")\n","                f.write(\"WHY IT HAPPENS:\\n\")\n","                f.write(\"  • Model outputs similar text even when understanding is shallow\\n\")\n","                f.write(\"  • Text similarity ≠ semantic correctness\\n\")\n","                f.write(\"  • Early iterations can be confidently wrong\\n\\n\")\n","                f.write(\"RECOMMENDATIONS:\\n\")\n","                f.write(\"  1. Increase minimum iterations (e.g., 3-4 instead of 2)\\n\")\n","                f.write(\"  2. Add quality assessment alongside similarity\\n\")\n","                f.write(\"  3. Require improvement plateau, not just similarity\\n\")\n","                f.write(\"  4. Use semantic similarity (embeddings) instead of text similarity\\n\")\n","\n","            elif failure_analysis['failure_type'] == 'Type B: No Convergence':\n","                f.write(\"PROBLEM: The stopping rule never triggered because responses kept\\n\")\n","                f.write(\"changing across iterations, never reaching the similarity threshold.\\n\\n\")\n","                f.write(\"WHY IT HAPPENS:\\n\")\n","                f.write(\"  • Model is uncertain and oscillates between interpretations\\n\")\n","                f.write(\"  • Each iteration introduces new perspectives without convergence\\n\")\n","                f.write(\"  • Iterative refinement doesn't help for ambiguous cases\\n\\n\")\n","                f.write(\"RECOMMENDATIONS:\\n\")\n","                f.write(\"  1. Detect oscillation pattern and stop early\\n\")\n","                f.write(\"  2. Lower threshold for difficult cases (e.g., 0.75)\\n\")\n","                f.write(\"  3. Use maximum iteration limit as backup\\n\")\n","                f.write(\"  4. Consider that iteration may not help - try different approach\\n\")\n","\n","            elif failure_analysis['failure_type'] == 'Type C: Post-Degradation Stop':\n","                f.write(\"PROBLEM: Quality peaked mid-iteration but the model continued,\\n\")\n","                f.write(\"degrading quality before eventually reaching similarity threshold.\\n\\n\")\n","                f.write(\"WHY IT HAPPENS:\\n\")\n","                f.write(\"  • Model overthinks and introduces errors\\n\")\n","                f.write(\"  • Similarity threshold reached after quality already declined\\n\")\n","                f.write(\"  • Later iterations compound errors from previous iterations\\n\\n\")\n","                f.write(\"RECOMMENDATIONS:\\n\")\n","                f.write(\"  1. Track quality trajectory alongside similarity\\n\")\n","                f.write(\"  2. Stop when quality decreases significantly (e.g., >10% drop)\\n\")\n","                f.write(\"  3. Implement 'peak detection' to stop at quality maximum\\n\")\n","                f.write(\"  4. Use ensemble of early iterations instead of continuing\\n\")\n","\n","        print(f\"✓ Failure trace saved: {trace_file}\")\n","\n","\n","class VideoLoader:\n","    \"\"\"Load and sample video frames\"\"\"\n","\n","    def __init__(self, data_dir, frame_skip=90):\n","        self.data_dir = data_dir\n","        self.frame_skip = frame_skip\n","\n","    def discover_videos(self):\n","        \"\"\"Discover all videos\"\"\"\n","        print(f\"\\n=== DISCOVERING VIDEOS ===\")\n","        print(f\"Scanning: {self.data_dir}\")\n","\n","        all_videos = {}\n","\n","        try:\n","            crime_types = [d for d in os.listdir(self.data_dir)\n","                          if os.path.isdir(os.path.join(self.data_dir, d))]\n","\n","            print(f\"Found {len(crime_types)} crime types: {crime_types}\")\n","\n","            for crime_type in crime_types:\n","                crime_dir = os.path.join(self.data_dir, crime_type)\n","                all_files = os.listdir(crime_dir)\n","\n","                video_groups = defaultdict(list)\n","\n","                for filename in all_files:\n","                    if not any(filename.lower().endswith(ext)\n","                             for ext in ['.png', '.jpg', '.jpeg', '.bmp']):\n","                        continue\n","\n","                    video_id = self._extract_video_id(filename)\n","                    if video_id:\n","                        video_groups[video_id].append(filename)\n","\n","                print(f\"  {crime_type}: {len(video_groups)} videos\")\n","\n","                for video_id, frames in video_groups.items():\n","                    all_videos[f\"{crime_type}_{video_id}\"] = {\n","                        'crime_type': crime_type,\n","                        'video_id': video_id,\n","                        'frames': sorted(frames, key=self._extract_frame_number),\n","                        'crime_dir': crime_dir\n","                    }\n","\n","        except Exception as e:\n","            print(f\"Error: {str(e)}\")\n","\n","        print(f\"Total videos: {len(all_videos)}\")\n","        return all_videos\n","\n","    def _extract_video_id(self, filename):\n","        \"\"\"Extract video ID from filename\"\"\"\n","        import re\n","        name_without_ext = os.path.splitext(filename)[0]\n","\n","        if '_frame_' in name_without_ext:\n","            return name_without_ext.split('_frame_')[0]\n","\n","        parts = name_without_ext.split('_')\n","        if len(parts) >= 2:\n","            try:\n","                int(parts[-1])\n","                return '_'.join(parts[:-1])\n","            except ValueError:\n","                pass\n","\n","        video_id = re.sub(r'_?\\d+$', '', name_without_ext)\n","        if video_id and video_id != name_without_ext:\n","            return video_id\n","\n","        return name_without_ext\n","\n","    def _extract_frame_number(self, filename):\n","        \"\"\"Extract frame number for sorting\"\"\"\n","        import re\n","        try:\n","            if '_frame_' in filename:\n","                parts = filename.split('_frame_')\n","                if len(parts) > 1:\n","                    return int(parts[1].split('.')[0])\n","            numbers = re.findall(r'\\d+', filename)\n","            if numbers:\n","                return int(numbers[-1])\n","        except:\n","            pass\n","        return 0\n","\n","    def load_video_frames(self, video_info):\n","        \"\"\"Load frames (every Nth frame)\"\"\"\n","        crime_dir = video_info['crime_dir']\n","        all_frames = video_info['frames']\n","\n","        selected_frames = all_frames[::self.frame_skip]\n","\n","        frames_data = []\n","        for frame_file in selected_frames:\n","            frame_path = os.path.join(crime_dir, frame_file)\n","            try:\n","                with open(frame_path, 'rb') as f:\n","                    frame_data = base64.b64encode(f.read()).decode('utf-8')\n","                    frames_data.append(frame_data)\n","            except Exception as e:\n","                print(f\"  Error loading {frame_file}: {str(e)}\")\n","\n","        print(f\"  Loaded {len(frames_data)} frames (every {self.frame_skip}th)\")\n","        return frames_data\n","\n","\n","def main():\n","    \"\"\"Main execution\"\"\"\n","    print(\"\\n\" + \"╔\" + \"=\"*78 + \"╗\")\n","    print(\"║\" + \" \"*12 + \"SIMILARITY-BASED STOPPING DIAGNOSTIC ANALYSIS\" + \" \"*21 + \"║\")\n","    print(\"║\" + \" \"*10 + \"Explicit Metrics, Thresholds & Failure Cases\" + \" \"*23 + \"║\")\n","    print(\"╚\" + \"=\"*78 + \"╝\\n\")\n","\n","    print(f\"STOPPING RULE CONFIGURATION:\")\n","    print(f\"  • Similarity Metric: {SIMILARITY_METRIC}\")\n","    print(f\"  • Similarity Threshold: {SIMILARITY_THRESHOLD}\")\n","    print(f\"  • Embedding Model: {EMBEDDING_MODEL}\")\n","    print(f\"  • Minimum Iterations: {MIN_ITERATIONS}\")\n","    print(f\"  • Maximum Iterations: {MAX_ITERATIONS}\")\n","    print()\n","\n","    # Load API key\n","    print(\"Loading API key...\")\n","    try:\n","        with open(API_KEY_PATH, 'r') as f:\n","            api_key = f.read().strip()\n","        if not api_key:\n","            print(\"✗ API key file is empty\")\n","            return\n","        print(\"✓ API key loaded\")\n","    except Exception as e:\n","        print(f\"✗ Error loading API key: {str(e)}\")\n","        return\n","\n","    # Test API\n","    print(\"\\nTesting Claude API...\")\n","    try:\n","        client = anthropic.Anthropic(api_key=api_key)\n","        response = client.messages.create(\n","            model=\"claude-sonnet-4-20250514\",\n","            max_tokens=50,\n","            messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n","        )\n","        print(\"✓ API connection successful\")\n","    except Exception as e:\n","        print(f\"✗ API test failed: {str(e)}\")\n","        return\n","\n","    # Initialize components\n","    print(\"\\nInitializing components...\")\n","    diagnostic = ClaudeIterativeDiagnostic(api_key)\n","    loader = VideoLoader(DATA_DIR, frame_skip=FRAME_SKIP)\n","\n","    # Discover videos\n","    all_videos = loader.discover_videos()\n","\n","    if not all_videos:\n","        print(\"✗ No videos found\")\n","        return\n","\n","    # Process videos\n","    print(f\"\\nProcessing up to 5 videos for similarity-based stopping analysis...\")\n","\n","    results = []\n","    failure_cases = []\n","\n","    for video_key, video_info in list(all_videos.items())[:5]:\n","        print(f\"\\n{'='*80}\")\n","        print(f\"VIDEO: {video_key}\")\n","        print(f\"{'='*80}\")\n","\n","        try:\n","            # Load frames\n","            frames_data = loader.load_video_frames(video_info)\n","\n","            if not frames_data:\n","                print(\"  ✗ No frames loaded\")\n","                continue\n","\n","            # Run similarity-based stopping analysis\n","            trace, stopping_analysis = diagnostic.process_video_with_similarity_stopping(\n","                frames_data,\n","                video_info['video_id'],\n","                video_info['crime_type']\n","            )\n","\n","            result = {\n","                'video_key': video_key,\n","                'trace': trace,\n","                'stopping_analysis': stopping_analysis\n","            }\n","            results.append(result)\n","\n","            # Track failure cases\n","            if stopping_analysis['failure_analysis']['failed']:\n","                failure_cases.append(result)\n","\n","        except Exception as e:\n","            print(f\"  ✗ Error processing {video_key}: {str(e)}\")\n","            import traceback\n","            traceback.print_exc()\n","\n","    # Generate summary report\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"GENERATING SUMMARY REPORT\")\n","    print(\"=\"*80 + \"\\n\")\n","\n","    summary_file = os.path.join(\n","        SAVE_DIR,\n","        f\"similarity_stopping_summary_{time.strftime('%Y%m%d_%H%M%S')}.txt\"\n","    )\n","\n","    with open(summary_file, 'w') as f:\n","        f.write(\"=\"*80 + \"\\n\")\n","        f.write(\"SIMILARITY-BASED STOPPING RULE ANALYSIS - SUMMARY REPORT\\n\")\n","        f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        f.write(\"STOPPING RULE SPECIFICATION:\\n\")\n","        f.write(f\"  • Similarity Metric: {SIMILARITY_METRIC}\\n\")\n","        f.write(f\"    - Algorithm: Ratcliff/Obershelp (difflib.SequenceMatcher)\\n\")\n","        f.write(f\"    - Formula: 2*M/T where M=matching chars, T=total chars\\n\")\n","        f.write(f\"  • Similarity Threshold: {SIMILARITY_THRESHOLD}\\n\")\n","        f.write(f\"  • Embedding Model: {EMBEDDING_MODEL}\\n\")\n","        f.write(f\"  • Minimum Iterations: {MIN_ITERATIONS}\\n\")\n","        f.write(f\"  • Maximum Iterations: {MAX_ITERATIONS}\\n\\n\")\n","\n","        f.write(f\"VIDEOS ANALYZED: {len(results)}\\n\")\n","        f.write(f\"FAILURE CASES: {len(failure_cases)} ({len(failure_cases)/max(len(results),1)*100:.1f}%)\\n\\n\")\n","\n","        f.write(\"=\"*80 + \"\\n\")\n","        f.write(\"STOPPING BEHAVIOR BY VIDEO\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        for result in results:\n","            f.write(f\"Video: {result['video_key']}\\n\")\n","            f.write(f\"  Stopped Early: {result['stopping_analysis']['stopped_early']}\\n\")\n","            if result['stopping_analysis']['stopped_early']:\n","                f.write(f\"  Stop Iteration: {result['stopping_analysis']['stop_iteration']}\\n\")\n","            f.write(f\"  Total Iterations: {result['stopping_analysis']['total_iterations']}\\n\")\n","\n","            if result['stopping_analysis']['failure_analysis']['failed']:\n","                f.write(f\"  ⚠ FAILURE: {result['stopping_analysis']['failure_analysis']['failure_type']}\\n\")\n","                f.write(f\"     {result['stopping_analysis']['failure_analysis']['description']}\\n\")\n","\n","            f.write(\"\\n\")\n","\n","        if failure_cases:\n","            f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","            f.write(\"DETAILED FAILURE CASE ANALYSIS\\n\")\n","            f.write(\"=\"*80 + \"\\n\\n\")\n","\n","            failure_type_counts = defaultdict(int)\n","            for failure in failure_cases:\n","                failure_type = failure['stopping_analysis']['failure_analysis']['failure_type']\n","                failure_type_counts[failure_type] += 1\n","\n","            f.write(\"FAILURE TYPE DISTRIBUTION:\\n\")\n","            for ftype, count in failure_type_counts.items():\n","                pct = (count / len(failure_cases)) * 100\n","                f.write(f\"  • {ftype}: {count} ({pct:.1f}%)\\n\")\n","\n","            f.write(\"\\n\\nFAILURE MECHANISMS:\\n\\n\")\n","\n","            for i, failure in enumerate(failure_cases, 1):\n","                f.write(f\"{i}. {failure['video_key']}\\n\")\n","                f.write(f\"   Type: {failure['stopping_analysis']['failure_analysis']['failure_type']}\\n\")\n","                f.write(f\"   Mechanism: {failure['stopping_analysis']['failure_analysis']['description']}\\n\")\n","\n","                evidence = failure['stopping_analysis']['failure_analysis']['supporting_evidence']\n","                f.write(\"   Evidence:\\n\")\n","                for key, value in evidence.items():\n","                    if isinstance(value, list):\n","                        f.write(f\"     • {key}: {[f'{v:.3f}' if isinstance(v, float) else v for v in value]}\\n\")\n","                    elif isinstance(value, float):\n","                        f.write(f\"     • {key}: {value:.3f}\\n\")\n","                    else:\n","                        f.write(f\"     • {key}: {value}\\n\")\n","                f.write(\"\\n\")\n","\n","        f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n","        f.write(\"RECOMMENDATIONS FOR PUBLICATION\\n\")\n","        f.write(\"=\"*80 + \"\\n\\n\")\n","\n","        f.write(\"1. CLEARLY SPECIFY THE STOPPING RULE IN YOUR PAPER:\\n\")\n","        f.write(f\"   • Metric: {SIMILARITY_METRIC} (Ratcliff/Obershelp algorithm)\\n\")\n","        f.write(f\"   • Threshold: {SIMILARITY_THRESHOLD}\\n\")\n","        f.write(f\"   • Minimum iterations: {MIN_ITERATIONS}\\n\")\n","        f.write(f\"   • Stopping condition: similarity(response_i, response_i-1) >= {SIMILARITY_THRESHOLD}\\n\\n\")\n","\n","        f.write(\"2. REPORT FAILURE RATE:\\n\")\n","        f.write(f\"   • {len(failure_cases)}/{len(results)} cases ({len(failure_cases)/max(len(results),1)*100:.1f}%) failed\\n\")\n","        f.write(\"   • Include failure type distribution\\n\")\n","        f.write(\"   • Explain each failure mechanism\\n\\n\")\n","\n","        f.write(\"3. INCLUDE CONCRETE TRACES:\\n\")\n","        f.write(\"   • Select 1-2 representative failure traces\\n\")\n","        f.write(\"   • Show iteration-by-iteration similarity scores\\n\")\n","        f.write(\"   • Demonstrate how errors compound or fail to converge\\n\")\n","        f.write(f\"   • See FAILURE_TRACE_*.txt files in {SAVE_DIR}/\\n\\n\")\n","\n","        f.write(\"4. DISCUSS LIMITATIONS:\\n\")\n","        f.write(\"   • Text similarity ≠ semantic correctness\\n\")\n","        f.write(\"   • High similarity can occur with wrong answers\\n\")\n","        f.write(\"   • Threshold choice is arbitrary and task-dependent\\n\")\n","        f.write(\"   • Consider alternative stopping criteria (quality-based, etc.)\\n\")\n","\n","    print(f\"✓ Summary report saved: {summary_file}\")\n","\n","    # Final summary\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"ANALYSIS COMPLETE\")\n","    print(\"=\"*80)\n","    print(f\"\\nResults:\")\n","    print(f\"  • Videos analyzed: {len(results)}\")\n","    print(f\"  • Failure cases: {len(failure_cases)} ({len(failure_cases)/max(len(results),1)*100:.1f}%)\")\n","    print(f\"\\nGenerated files:\")\n","    print(f\"  • Detailed analyses: {len(results)} files\")\n","    print(f\"  • Failure traces: {len(failure_cases)} files\")\n","    print(f\"  • Summary report: 1 file\")\n","    print(f\"\\nAll files saved to: {SAVE_DIR}/\")\n","\n","    if failure_cases:\n","        print(\"\\n⚠ FAILURE CASES DETECTED:\")\n","        failure_type_counts = defaultdict(int)\n","        for failure in failure_cases:\n","            failure_type = failure['stopping_analysis']['failure_analysis']['failure_type']\n","            failure_type_counts[failure_type] += 1\n","\n","        for ftype, count in failure_type_counts.items():\n","            pct = (count / len(failure_cases)) * 100\n","            print(f\"  • {ftype}: {count} ({pct:.1f}%)\")\n","\n","        print(\"\\n✓ Use FAILURE_TRACE_*.txt files in your paper!\")\n","        print(\"  These provide concrete examples addressing the reviewer's concern.\")\n","\n","    print(\"\\n\" + \"=\"*80)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}